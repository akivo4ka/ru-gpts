{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ruGPT3_medium_psy_train_run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IQejg-ITzBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106bbfd8-9556-4228-a63d-5d4df4d9caee"
      },
      "source": [
        "# Клонируем репозиторий... \n",
        "!git clone https://github.com/akivo4ka/ru-gpts.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ru-gpts'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 299 (delta 16), reused 33 (delta 11), pack-reused 253\u001b[K\n",
            "Receiving objects: 100% (299/299), 5.67 MiB | 23.90 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoYGkWmXT0ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffd6e2e-88b7-49be-8cf6-1d3f54c08f6c"
      },
      "source": [
        "!python -m pip install virtualenv\n",
        "!virtualenv gpt_env\n",
        "!source gpt_env/bin/activate\n",
        "!pip install --upgrade setuptools\n",
        "!pip install -r ./ru-gpts/requirements.txt\n",
        "!pip install python-telegram-bot\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5b/ba305d88fc81c4e8929d5e8e52542e994339f410d2692dfe585ae70e0e8e/virtualenv-20.2.0-py2.py3-none-any.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.0.12)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata<3,>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (2.0.0)\n",
            "Requirement already satisfied: importlib-resources>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.3.0)\n",
            "Collecting appdirs<2,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting distlib<1,>=0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/0a/490fa011d699bb5a5f3a0cf57de82237f52a6db9d40f33c53b2736c9a1f9/distlib-0.3.1-py2.py3-none-any.whl (335kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<3,>=0.12; python_version < \"3.8\"->virtualenv) (3.4.0)\n",
            "Installing collected packages: appdirs, distlib, virtualenv\n",
            "Successfully installed appdirs-1.4.4 distlib-0.3.1 virtualenv-20.2.0\n",
            "created virtual environment CPython3.6.9.final.0-64 in 706ms\n",
            "  creator CPython3Posix(dest=/content/gpt_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==20.2.4, setuptools==50.3.2, wheel==0.35.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (50.3.2)\n",
            "Collecting nltk>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from -r ./ru-gpts/requirements.txt (line 2)) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from -r ./ru-gpts/requirements.txt (line 3)) (1.1.4)\n",
            "Collecting sentencepiece>=0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r ./ru-gpts/requirements.txt (line 5)) (2.3.0)\n",
            "Collecting boto3==1.11.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f7/d8c122725ab80fa58076be793e5392022d6557f54f77e6ef46436682fb71/boto3-1.11.11-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 54.8MB/s \n",
            "\u001b[?25hCollecting regex==2020.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/64/1b0eb918ebdfba27b4c148853ed93cc38d83aa452882f2a9dc64acaa9b2f/regex-2020.1.8-cp36-cp36m-manylinux2010_x86_64.whl (689kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 48.4MB/s \n",
            "\u001b[?25hCollecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r ./ru-gpts/requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r ./ru-gpts/requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r ./ru-gpts/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->-r ./ru-gpts/requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->-r ./ru-gpts/requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.1.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25hCollecting botocore<1.15.0,>=1.14.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/bc/788364aeb7d969a38c9d2295f95f1315a2ef49163f9b71d06de8c5ef0754/botocore-1.14.17-py2.py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 53.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (0.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (3.3.3)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.11->boto3==1.11.11->-r ./ru-gpts/requirements.txt (line 6)) (1.24.3)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r ./ru-gpts/requirements.txt (line 8)) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r ./ru-gpts/requirements.txt (line 5)) (3.4.0)\n",
            "Building wheels for collected packages: nltk, sacremoses\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434674 sha256=9aed1fd886ddbb917438a1a4308fd921739017e84e03d75a04917f60af2fd12d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=208065bd422433ef930e1c8fc5254ad8127d6c26c12875c1016c5c37aa50e8ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built nltk sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: regex, nltk, sentencepiece, jmespath, docutils, botocore, s3transfer, boto3, tokenizers, sacremoses, transformers\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "Successfully installed boto3-1.11.11 botocore-1.14.17 docutils-0.15.2 jmespath-0.10.0 nltk-3.5 regex-2020.1.8 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.8.0\n",
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/ad/e86f885ab66e54a5f813131e03bd8682ee0b3d2b6a2cde53ed7828b9ef0a/python_telegram_bot-13.0-py2.py3-none-any.whl (404kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Requirement already satisfied: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (4.4.2)\n",
            "Collecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2020.6.20)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (50.3.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.20)\n",
            "Installing collected packages: APScheduler, cryptography, python-telegram-bot\n",
            "Successfully installed APScheduler-3.6.3 cryptography-3.2.1 python-telegram-bot-13.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.11)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.11 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.17)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.11->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.11->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urqMSX0PZoMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556e0268-c628-4e90-97c0-770cdd41a4db"
      },
      "source": [
        "%%writefile setup_apex.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup_apex.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnUy6xvFZtVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4884964-63b9-4c03-8f24-316f8aa64472"
      },
      "source": [
        "!sh setup_apex.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 7456, done.\u001b[K\n",
            "remote: Total 7456 (delta 0), reused 0 (delta 0), pack-reused 7456\u001b[K\n",
            "Receiving objects: 100% (7456/7456), 13.91 MiB | 26.63 MiB/s, done.\n",
            "Resolving deltas: 100% (5036/5036), done.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-oq0n_2ts\n",
            "Created temporary directory: /tmp/pip-req-tracker-6yly8t2x\n",
            "Created requirements tracker '/tmp/pip-req-tracker-6yly8t2x'\n",
            "Created temporary directory: /tmp/pip-install-k4zgpyo4\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-04yq2mc3\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-6yly8t2x'\n",
            "    Running setup.py (path:/tmp/pip-req-build-04yq2mc3/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.7.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-04yq2mc3/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-04yq2mc3/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-04yq2mc3 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-6yly8t2x'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-ydhz8tr1\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-04yq2mc3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-04yq2mc3/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-ydhz8tr1/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.7.0+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-04yq2mc3/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/amp_C_frontend.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/syncbn.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:171:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-ydhz8tr1/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-04yq2mc3\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-6yly8t2x'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S44TB7CUT3A9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29de7b3-e885-4fe9-983e-56d3b6a64cf1"
      },
      "source": [
        "!python ./ru-gpts/pretrain_transformers.py \\\n",
        "    --model_type=gpt3 \\\n",
        "    --output_dir=./ruGPT3medium_psy \\\n",
        "    --train_data_file=./ru-gpts/parsers/all.txt \\\n",
        "    --do_train \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3medium_based_on_gpt2 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --overwrite_cache \\\n",
        "    --block_size=1024 \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --fp16"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-22 13:10:13.106099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/22/2020 13:10:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140070243352 acquired on /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpmu458ybz\n",
            "Downloading: 100% 674/674 [00:00<00:00, 929kB/s]\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/config.json in cache at /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140070243352 released on /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/config.json from cache at /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1\n",
            "11/22/2020 13:10:15 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": null,\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"n_special\": 0,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/22/2020 13:10:15 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/config.json from cache at /root/.cache/torch/transformers/de532b2dc8525a100f796ff660b6ecc57e6e6b7a6ab5892614ebb8cdfc107fba.a2ab8be3b95d09ab7231f8496a99743ed3656b47fea0396c9b5ebb851dd136c1\n",
            "11/22/2020 13:10:15 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": null,\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"n_special\": 0,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   Model name 'sberbank-ai/rugpt3medium_based_on_gpt2' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'sberbank-ai/rugpt3medium_based_on_gpt2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140456454016 acquired on /root/.cache/torch/transformers/89bf2b81c643257c376e6627a06fa02469410fc8febbfdcb293ba29d5df1aace.eafd10ce90058b94ee9d02c8163ea11470b45b629761a6da290aa3c19d751f8f.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpqyhtscet\n",
            "Downloading: 100% 1.61M/1.61M [00:00<00:00, 43.9MB/s]\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/vocab.json in cache at /root/.cache/torch/transformers/89bf2b81c643257c376e6627a06fa02469410fc8febbfdcb293ba29d5df1aace.eafd10ce90058b94ee9d02c8163ea11470b45b629761a6da290aa3c19d751f8f\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/89bf2b81c643257c376e6627a06fa02469410fc8febbfdcb293ba29d5df1aace.eafd10ce90058b94ee9d02c8163ea11470b45b629761a6da290aa3c19d751f8f\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140456454016 released on /root/.cache/torch/transformers/89bf2b81c643257c376e6627a06fa02469410fc8febbfdcb293ba29d5df1aace.eafd10ce90058b94ee9d02c8163ea11470b45b629761a6da290aa3c19d751f8f.lock\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140070203176 acquired on /root/.cache/torch/transformers/b2e3fd73df6b2e2f895987b5695e090c3da9f69c36b17f092b44c7c438c82b12.1ec899ae22f4f1a24df00771f19dbb9bea4de59cab4e62308e785c755c933050.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp30ywcc5c\n",
            "Downloading: 100% 1.27M/1.27M [00:00<00:00, 37.8MB/s]\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/merges.txt in cache at /root/.cache/torch/transformers/b2e3fd73df6b2e2f895987b5695e090c3da9f69c36b17f092b44c7c438c82b12.1ec899ae22f4f1a24df00771f19dbb9bea4de59cab4e62308e785c755c933050\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b2e3fd73df6b2e2f895987b5695e090c3da9f69c36b17f092b44c7c438c82b12.1ec899ae22f4f1a24df00771f19dbb9bea4de59cab4e62308e785c755c933050\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140070203176 released on /root/.cache/torch/transformers/b2e3fd73df6b2e2f895987b5695e090c3da9f69c36b17f092b44c7c438c82b12.1ec899ae22f4f1a24df00771f19dbb9bea4de59cab4e62308e785c755c933050.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/vocab.json from cache at /root/.cache/torch/transformers/89bf2b81c643257c376e6627a06fa02469410fc8febbfdcb293ba29d5df1aace.eafd10ce90058b94ee9d02c8163ea11470b45b629761a6da290aa3c19d751f8f\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/merges.txt from cache at /root/.cache/torch/transformers/b2e3fd73df6b2e2f895987b5695e090c3da9f69c36b17f092b44c7c438c82b12.1ec899ae22f4f1a24df00771f19dbb9bea4de59cab4e62308e785c755c933050\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/added_tokens.json from cache at None\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/special_tokens_map.json from cache at None\n",
            "11/22/2020 13:10:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/tokenizer_config.json from cache at None\n",
            "11/22/2020 13:10:15 - INFO - filelock -   Lock 140140070202280 acquired on /root/.cache/torch/transformers/0c4e4568067f849f4d1b54e2105b56120b1753d8fc106b8d50ff77423f4c82e6.5650828ce6419a1816a6b56f8c7f4f9a8e4ff77712fe7e96d16d8303dac0ffde.lock\n",
            "11/22/2020 13:10:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9ddb2ffn\n",
            "Downloading: 100% 1.73G/1.73G [00:44<00:00, 39.1MB/s]\n",
            "11/22/2020 13:11:00 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/pytorch_model.bin in cache at /root/.cache/torch/transformers/0c4e4568067f849f4d1b54e2105b56120b1753d8fc106b8d50ff77423f4c82e6.5650828ce6419a1816a6b56f8c7f4f9a8e4ff77712fe7e96d16d8303dac0ffde\n",
            "11/22/2020 13:11:00 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/0c4e4568067f849f4d1b54e2105b56120b1753d8fc106b8d50ff77423f4c82e6.5650828ce6419a1816a6b56f8c7f4f9a8e4ff77712fe7e96d16d8303dac0ffde\n",
            "11/22/2020 13:11:00 - INFO - filelock -   Lock 140140070202280 released on /root/.cache/torch/transformers/0c4e4568067f849f4d1b54e2105b56120b1753d8fc106b8d50ff77423f4c82e6.5650828ce6419a1816a6b56f8c7f4f9a8e4ff77712fe7e96d16d8303dac0ffde.lock\n",
            "11/22/2020 13:11:00 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3medium_based_on_gpt2/pytorch_model.bin from cache at /root/.cache/torch/transformers/0c4e4568067f849f4d1b54e2105b56120b1753d8fc106b8d50ff77423f4c82e6.5650828ce6419a1816a6b56f8c7f4f9a8e4ff77712fe7e96d16d8303dac0ffde\n",
            "11/22/2020 13:11:13 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in GPT2LMHeadModel: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.masked_bias']\n",
            "11/22/2020 13:11:28 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=False, do_train=True, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, fp16=True, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='sberbank-ai/rugpt3medium_based_on_gpt2', model_type='gpt3', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='./ruGPT3medium_psy', overwrite_cache=True, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='./ru-gpts/parsers/all.txt', warmup_steps=0, weight_decay=0.01)\n",
            "11/22/2020 13:11:28 - INFO - __main__ -   Creating features from dataset file at ./ru-gpts/parsers\n",
            "11/22/2020 13:11:53 - INFO - __main__ -   Saving features into cached file ./ru-gpts/parsers/gpt3_cached_lm_1024_all.txt\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "11/22/2020 13:11:53 - INFO - __main__ -   ***** Running training *****\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Num examples = 2008\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Num Epochs = 1\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "11/22/2020 13:11:53 - INFO - __main__ -     Total optimization steps = 2008\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/2008 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py:101: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  return orig_fn(arg0, *args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\n",
            "Iteration:   0% 1/2008 [00:01<56:55,  1.70s/it]\u001b[A\n",
            "Iteration:   0% 2/2008 [00:02<45:59,  1.38s/it]\u001b[A\n",
            "Iteration:   0% 3/2008 [00:02<38:29,  1.15s/it]\u001b[A\n",
            "Iteration:   0% 4/2008 [00:03<33:10,  1.01it/s]\u001b[A\n",
            "Iteration:   0% 5/2008 [00:04<29:29,  1.13it/s]\u001b[A\n",
            "Iteration:   0% 6/2008 [00:04<26:54,  1.24it/s]\u001b[A\n",
            "Iteration:   0% 7/2008 [00:05<25:09,  1.33it/s]\u001b[A\n",
            "Iteration:   0% 8/2008 [00:06<24:00,  1.39it/s]\u001b[A\n",
            "Iteration:   0% 9/2008 [00:06<23:03,  1.44it/s]\u001b[A\n",
            "Iteration:   0% 10/2008 [00:07<22:23,  1.49it/s]\u001b[A\n",
            "Iteration:   1% 11/2008 [00:07<21:57,  1.52it/s]\u001b[A\n",
            "Iteration:   1% 12/2008 [00:08<21:39,  1.54it/s]\u001b[A\n",
            "Iteration:   1% 13/2008 [00:09<21:24,  1.55it/s]\u001b[A\n",
            "Iteration:   1% 14/2008 [00:09<21:15,  1.56it/s]\u001b[A\n",
            "Iteration:   1% 15/2008 [00:10<21:06,  1.57it/s]\u001b[A\n",
            "Iteration:   1% 16/2008 [00:11<21:04,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 17/2008 [00:11<20:59,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 18/2008 [00:12<20:56,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 19/2008 [00:13<20:56,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 20/2008 [00:13<20:55,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 21/2008 [00:14<20:55,  1.58it/s]\u001b[A\n",
            "Iteration:   1% 22/2008 [00:14<20:52,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 23/2008 [00:15<20:50,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 24/2008 [00:16<20:48,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 25/2008 [00:16<20:46,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 26/2008 [00:17<20:44,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 27/2008 [00:18<20:44,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 28/2008 [00:18<20:47,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 29/2008 [00:19<20:47,  1.59it/s]\u001b[A\n",
            "Iteration:   1% 30/2008 [00:19<20:47,  1.59it/s]\u001b[A\n",
            "Iteration:   2% 31/2008 [00:20<20:44,  1.59it/s]\u001b[A\n",
            "Iteration:   2% 32/2008 [00:21<20:50,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 33/2008 [00:21<20:47,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 34/2008 [00:22<20:47,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 35/2008 [00:23<20:46,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 36/2008 [00:23<20:48,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 37/2008 [00:24<20:45,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 38/2008 [00:25<20:48,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 39/2008 [00:25<20:45,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 40/2008 [00:26<20:46,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 41/2008 [00:26<20:45,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 42/2008 [00:27<20:46,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 43/2008 [00:28<20:43,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 44/2008 [00:28<20:44,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 45/2008 [00:29<20:46,  1.57it/s]\u001b[A\n",
            "Iteration:   2% 46/2008 [00:30<20:43,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 47/2008 [00:30<20:44,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 48/2008 [00:31<20:44,  1.58it/s]\u001b[A\n",
            "Iteration:   2% 49/2008 [00:31<20:45,  1.57it/s]\u001b[A\n",
            "Iteration:   2% 50/2008 [00:32<20:45,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 51/2008 [00:33<20:46,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 52/2008 [00:33<20:50,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 53/2008 [00:34<20:44,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 54/2008 [00:35<20:46,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 55/2008 [00:35<20:42,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 56/2008 [00:36<20:49,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 57/2008 [00:37<20:46,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 58/2008 [00:37<20:45,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 59/2008 [00:38<20:40,  1.57it/s]\u001b[A\n",
            "Iteration:   3% 60/2008 [00:39<20:46,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 61/2008 [00:39<20:45,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 62/2008 [00:40<20:48,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 63/2008 [00:40<20:46,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 64/2008 [00:41<20:48,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 65/2008 [00:42<20:51,  1.55it/s]\u001b[A\n",
            "Iteration:   3% 66/2008 [00:42<20:48,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 67/2008 [00:43<20:42,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 68/2008 [00:44<20:42,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 69/2008 [00:44<20:39,  1.56it/s]\u001b[A\n",
            "Iteration:   3% 70/2008 [00:45<20:48,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 71/2008 [00:46<20:47,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 72/2008 [00:46<20:46,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 73/2008 [00:47<20:46,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 74/2008 [00:48<20:45,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 75/2008 [00:48<20:41,  1.56it/s]\u001b[A\n",
            "Iteration:   4% 76/2008 [00:49<20:42,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 77/2008 [00:49<20:41,  1.56it/s]\u001b[A\n",
            "Iteration:   4% 78/2008 [00:50<20:42,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 79/2008 [00:51<20:44,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 80/2008 [00:51<20:41,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 81/2008 [00:52<20:43,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 82/2008 [00:53<20:40,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 83/2008 [00:53<20:45,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 84/2008 [00:54<20:44,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 85/2008 [00:55<20:41,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 86/2008 [00:55<20:38,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 87/2008 [00:56<20:39,  1.55it/s]\u001b[A\n",
            "Iteration:   4% 88/2008 [00:57<20:43,  1.54it/s]\u001b[A\n",
            "Iteration:   4% 89/2008 [00:57<20:48,  1.54it/s]\u001b[A\n",
            "Iteration:   4% 90/2008 [00:58<20:47,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 91/2008 [00:59<20:44,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 92/2008 [00:59<20:41,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 93/2008 [01:00<20:40,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 94/2008 [01:00<20:38,  1.55it/s]\u001b[A\n",
            "Iteration:   5% 95/2008 [01:01<20:41,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 96/2008 [01:02<20:39,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 97/2008 [01:02<20:41,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 98/2008 [01:03<20:44,  1.53it/s]\u001b[A\n",
            "Iteration:   5% 99/2008 [01:04<20:47,  1.53it/s]\u001b[A\n",
            "Iteration:   5% 100/2008 [01:04<20:42,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 101/2008 [01:05<20:40,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 102/2008 [01:06<20:38,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 103/2008 [01:06<20:37,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 104/2008 [01:07<20:37,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 105/2008 [01:08<20:37,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 106/2008 [01:08<20:38,  1.54it/s]\u001b[A\n",
            "Iteration:   5% 107/2008 [01:09<20:41,  1.53it/s]\u001b[A\n",
            "Iteration:   5% 108/2008 [01:10<20:44,  1.53it/s]\u001b[A\n",
            "Iteration:   5% 109/2008 [01:10<20:49,  1.52it/s]\u001b[A\n",
            "Iteration:   5% 110/2008 [01:11<20:46,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 111/2008 [01:12<20:44,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 112/2008 [01:12<20:41,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 113/2008 [01:13<20:39,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 114/2008 [01:14<20:39,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 115/2008 [01:14<20:37,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 116/2008 [01:15<20:38,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 117/2008 [01:15<20:37,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 118/2008 [01:16<20:37,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 119/2008 [01:17<20:33,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 120/2008 [01:17<20:38,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 121/2008 [01:18<20:35,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 122/2008 [01:19<20:33,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 123/2008 [01:19<20:35,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 124/2008 [01:20<20:34,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 125/2008 [01:21<20:34,  1.53it/s]\u001b[A\n",
            "Iteration:   6% 126/2008 [01:21<20:40,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 127/2008 [01:22<20:37,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 128/2008 [01:23<20:35,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 129/2008 [01:23<20:36,  1.52it/s]\u001b[A\n",
            "Iteration:   6% 130/2008 [01:24<20:35,  1.52it/s]\u001b[A\n",
            "Iteration:   7% 131/2008 [01:25<20:36,  1.52it/s]\u001b[A\n",
            "Iteration:   7% 132/2008 [01:25<20:37,  1.52it/s]\u001b[A\n",
            "Iteration:   7% 133/2008 [01:26<20:39,  1.51it/s]\u001b[A\n",
            "Iteration:   7% 134/2008 [01:27<20:37,  1.51it/s]\u001b[A\n",
            "Iteration:   7% 135/2008 [01:27<20:34,  1.52it/s]\u001b[A\n",
            "Iteration:   7% 136/2008 [01:28<20:35,  1.52it/s]\u001b[A\n",
            "Iteration:   7% 137/2008 [01:29<20:37,  1.51it/s]\u001b[A\n",
            "Iteration:   7% 138/2008 [01:29<20:43,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 139/2008 [01:30<20:39,  1.51it/s]\u001b[A\n",
            "Iteration:   7% 140/2008 [01:31<20:46,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 141/2008 [01:31<20:43,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 142/2008 [01:32<20:42,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 143/2008 [01:33<20:44,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 144/2008 [01:33<20:47,  1.49it/s]\u001b[A\n",
            "Iteration:   7% 145/2008 [01:34<20:42,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 146/2008 [01:35<20:46,  1.49it/s]\u001b[A\n",
            "Iteration:   7% 147/2008 [01:35<20:39,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 148/2008 [01:36<20:42,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 149/2008 [01:37<20:39,  1.50it/s]\u001b[A\n",
            "Iteration:   7% 150/2008 [01:37<20:37,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 151/2008 [01:38<20:38,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 152/2008 [01:39<20:37,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 153/2008 [01:39<20:34,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 154/2008 [01:40<20:36,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 155/2008 [01:41<20:35,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 156/2008 [01:41<20:36,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 157/2008 [01:42<20:37,  1.50it/s]\u001b[A\n",
            "Iteration:   8% 158/2008 [01:43<20:39,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 159/2008 [01:43<20:41,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 160/2008 [01:44<20:40,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 161/2008 [01:45<20:40,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 162/2008 [01:45<20:38,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 163/2008 [01:46<20:35,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 164/2008 [01:47<20:36,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 165/2008 [01:47<20:40,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 166/2008 [01:48<20:40,  1.49it/s]\u001b[A\n",
            "Iteration:   8% 167/2008 [01:49<20:45,  1.48it/s]\u001b[A\n",
            "Iteration:   8% 168/2008 [01:49<20:40,  1.48it/s]\u001b[A\n",
            "Iteration:   8% 169/2008 [01:50<20:44,  1.48it/s]\u001b[A\n",
            "Iteration:   8% 170/2008 [01:51<20:43,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 171/2008 [01:51<20:41,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 172/2008 [01:52<20:42,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 173/2008 [01:53<20:38,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 174/2008 [01:53<20:38,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 175/2008 [01:54<20:38,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 176/2008 [01:55<20:37,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 177/2008 [01:55<20:43,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 178/2008 [01:56<20:39,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 179/2008 [01:57<20:40,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 180/2008 [01:58<20:43,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 181/2008 [01:58<20:37,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 182/2008 [01:59<20:38,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 183/2008 [02:00<20:41,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 184/2008 [02:00<20:35,  1.48it/s]\u001b[A\n",
            "Iteration:   9% 185/2008 [02:01<20:39,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 186/2008 [02:02<20:39,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 187/2008 [02:02<20:36,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 188/2008 [02:03<20:35,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 189/2008 [02:04<20:35,  1.47it/s]\u001b[A\n",
            "Iteration:   9% 190/2008 [02:04<20:29,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 191/2008 [02:05<20:26,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 192/2008 [02:06<20:25,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 193/2008 [02:06<20:31,  1.47it/s]\u001b[A\n",
            "Iteration:  10% 194/2008 [02:07<20:26,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 195/2008 [02:08<20:29,  1.47it/s]\u001b[A\n",
            "Iteration:  10% 196/2008 [02:08<20:24,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 197/2008 [02:09<20:23,  1.48it/s]\u001b[A\n",
            "Iteration:  10% 198/2008 [02:10<20:18,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 199/2008 [02:10<20:16,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 200/2008 [02:11<20:12,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 201/2008 [02:12<20:10,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 202/2008 [02:12<20:08,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 203/2008 [02:13<20:10,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 204/2008 [02:14<20:07,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 205/2008 [02:14<20:05,  1.50it/s]\u001b[A\n",
            "Iteration:  10% 206/2008 [02:15<20:07,  1.49it/s]\u001b[A\n",
            "Iteration:  10% 207/2008 [02:16<20:02,  1.50it/s]\u001b[A\n",
            "Iteration:  10% 208/2008 [02:16<20:01,  1.50it/s]\u001b[A\n",
            "Iteration:  10% 209/2008 [02:17<20:02,  1.50it/s]\u001b[A\n",
            "Iteration:  10% 210/2008 [02:18<19:59,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 211/2008 [02:18<20:01,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 212/2008 [02:19<20:01,  1.49it/s]\u001b[A\n",
            "Iteration:  11% 213/2008 [02:20<19:56,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 214/2008 [02:20<19:58,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 215/2008 [02:21<19:55,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 216/2008 [02:22<19:55,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 217/2008 [02:22<19:54,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 218/2008 [02:23<19:55,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 219/2008 [02:24<19:55,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 220/2008 [02:24<19:50,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 221/2008 [02:25<19:50,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 222/2008 [02:26<19:46,  1.51it/s]\u001b[A\n",
            "Iteration:  11% 223/2008 [02:26<19:44,  1.51it/s]\u001b[A\n",
            "Iteration:  11% 224/2008 [02:27<19:46,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 225/2008 [02:28<19:42,  1.51it/s]\u001b[A\n",
            "Iteration:  11% 226/2008 [02:28<19:46,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 227/2008 [02:29<19:42,  1.51it/s]\u001b[A\n",
            "Iteration:  11% 228/2008 [02:30<19:39,  1.51it/s]\u001b[A\n",
            "Iteration:  11% 229/2008 [02:30<19:43,  1.50it/s]\u001b[A\n",
            "Iteration:  11% 230/2008 [02:31<19:39,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 231/2008 [02:32<19:41,  1.50it/s]\u001b[A\n",
            "Iteration:  12% 232/2008 [02:32<19:38,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 233/2008 [02:33<19:39,  1.50it/s]\u001b[A\n",
            "Iteration:  12% 234/2008 [02:34<19:36,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 235/2008 [02:34<19:39,  1.50it/s]\u001b[A\n",
            "Iteration:  12% 236/2008 [02:35<19:33,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 237/2008 [02:36<19:33,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 238/2008 [02:36<19:31,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 239/2008 [02:37<19:34,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 240/2008 [02:38<19:32,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 241/2008 [02:38<19:32,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 242/2008 [02:39<19:30,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 243/2008 [02:40<19:30,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 244/2008 [02:40<19:31,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 245/2008 [02:41<19:29,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 246/2008 [02:42<19:28,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 247/2008 [02:42<19:27,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 248/2008 [02:43<19:28,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 249/2008 [02:44<19:25,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 250/2008 [02:44<19:26,  1.51it/s]\u001b[A\n",
            "Iteration:  12% 251/2008 [02:45<19:29,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 252/2008 [02:46<19:28,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 253/2008 [02:46<19:28,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 254/2008 [02:47<19:29,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 255/2008 [02:48<19:27,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 256/2008 [02:48<19:27,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 257/2008 [02:49<19:26,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 258/2008 [02:50<19:31,  1.49it/s]\u001b[A\n",
            "Iteration:  13% 259/2008 [02:50<19:25,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 260/2008 [02:51<19:26,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 261/2008 [02:52<19:24,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 262/2008 [02:52<19:22,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 263/2008 [02:53<19:25,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 264/2008 [02:54<19:20,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 265/2008 [02:54<19:21,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 266/2008 [02:55<19:22,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 267/2008 [02:56<19:20,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 268/2008 [02:56<19:24,  1.49it/s]\u001b[A\n",
            "Iteration:  13% 269/2008 [02:57<19:20,  1.50it/s]\u001b[A\n",
            "Iteration:  13% 270/2008 [02:58<19:23,  1.49it/s]\u001b[A\n",
            "Iteration:  13% 271/2008 [02:58<19:19,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 272/2008 [02:59<19:17,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 273/2008 [03:00<19:16,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 274/2008 [03:00<19:15,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 275/2008 [03:01<19:17,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 276/2008 [03:02<19:14,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 277/2008 [03:02<19:14,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 278/2008 [03:03<19:14,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 279/2008 [03:04<19:15,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 280/2008 [03:04<19:14,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 281/2008 [03:05<19:12,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 282/2008 [03:06<19:14,  1.49it/s]\u001b[A\n",
            "Iteration:  14% 283/2008 [03:06<19:12,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 284/2008 [03:07<19:12,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 285/2008 [03:08<19:11,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 286/2008 [03:08<19:09,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 287/2008 [03:09<19:11,  1.49it/s]\u001b[A\n",
            "Iteration:  14% 288/2008 [03:10<19:10,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 289/2008 [03:10<19:09,  1.50it/s]\u001b[A\n",
            "Iteration:  14% 290/2008 [03:11<19:11,  1.49it/s]\u001b[A\n",
            "Iteration:  14% 291/2008 [03:12<19:09,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 292/2008 [03:12<19:11,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 293/2008 [03:13<19:10,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 294/2008 [03:14<19:09,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 295/2008 [03:14<19:08,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 296/2008 [03:15<19:10,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 297/2008 [03:16<19:09,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 298/2008 [03:16<19:07,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 299/2008 [03:17<19:09,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 300/2008 [03:18<19:07,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 301/2008 [03:18<19:06,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 302/2008 [03:19<19:03,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 303/2008 [03:20<19:04,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 304/2008 [03:20<19:03,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 305/2008 [03:21<19:03,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 306/2008 [03:22<19:03,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 307/2008 [03:22<19:01,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 308/2008 [03:23<19:04,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 309/2008 [03:24<19:02,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 310/2008 [03:24<19:01,  1.49it/s]\u001b[A\n",
            "Iteration:  15% 311/2008 [03:25<19:01,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 312/2008 [03:26<18:56,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 313/2008 [03:26<18:55,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 314/2008 [03:27<18:52,  1.50it/s]\u001b[A\n",
            "Iteration:  16% 315/2008 [03:28<18:53,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 316/2008 [03:28<18:51,  1.50it/s]\u001b[A\n",
            "Iteration:  16% 317/2008 [03:29<18:52,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 318/2008 [03:30<18:50,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 319/2008 [03:30<18:50,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 320/2008 [03:31<18:50,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 321/2008 [03:32<18:52,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 322/2008 [03:32<18:47,  1.50it/s]\u001b[A\n",
            "Iteration:  16% 323/2008 [03:33<18:44,  1.50it/s]\u001b[A\n",
            "Iteration:  16% 324/2008 [03:34<18:42,  1.50it/s]\u001b[A\n",
            "Iteration:  16% 325/2008 [03:34<18:46,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 326/2008 [03:35<18:46,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 327/2008 [03:36<18:45,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 328/2008 [03:36<18:47,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 329/2008 [03:37<18:43,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 330/2008 [03:38<18:47,  1.49it/s]\u001b[A\n",
            "Iteration:  16% 331/2008 [03:39<18:43,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 332/2008 [03:39<18:40,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 333/2008 [03:40<18:38,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 334/2008 [03:41<18:43,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 335/2008 [03:41<18:39,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 336/2008 [03:42<18:39,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 337/2008 [03:43<18:40,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 338/2008 [03:43<18:36,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 339/2008 [03:44<18:36,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 340/2008 [03:45<18:34,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 341/2008 [03:45<18:37,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 342/2008 [03:46<18:38,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 343/2008 [03:47<18:35,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 344/2008 [03:47<18:32,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 345/2008 [03:48<18:30,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 346/2008 [03:49<18:32,  1.49it/s]\u001b[A\n",
            "Iteration:  17% 347/2008 [03:49<18:27,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 348/2008 [03:50<18:27,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 349/2008 [03:51<18:23,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 350/2008 [03:51<18:28,  1.50it/s]\u001b[A\n",
            "Iteration:  17% 351/2008 [03:52<18:23,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 352/2008 [03:53<18:26,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 353/2008 [03:53<18:21,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 354/2008 [03:54<18:21,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 355/2008 [03:55<18:21,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 356/2008 [03:55<18:22,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 357/2008 [03:56<18:22,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 358/2008 [03:57<18:25,  1.49it/s]\u001b[A\n",
            "Iteration:  18% 359/2008 [03:57<18:23,  1.49it/s]\u001b[A\n",
            "Iteration:  18% 360/2008 [03:58<18:21,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 361/2008 [03:59<18:21,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 362/2008 [03:59<18:18,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 363/2008 [04:00<18:16,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 364/2008 [04:01<18:17,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 365/2008 [04:01<18:15,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 366/2008 [04:02<18:15,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 367/2008 [04:03<18:14,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 368/2008 [04:03<18:18,  1.49it/s]\u001b[A\n",
            "Iteration:  18% 369/2008 [04:04<18:17,  1.49it/s]\u001b[A\n",
            "Iteration:  18% 370/2008 [04:05<18:14,  1.50it/s]\u001b[A\n",
            "Iteration:  18% 371/2008 [04:05<18:14,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 372/2008 [04:06<18:13,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 373/2008 [04:07<18:13,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 374/2008 [04:07<18:11,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 375/2008 [04:08<18:11,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 376/2008 [04:09<18:09,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 377/2008 [04:09<18:10,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 378/2008 [04:10<18:08,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 379/2008 [04:11<18:06,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 380/2008 [04:11<18:05,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 381/2008 [04:12<18:04,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 382/2008 [04:13<18:03,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 383/2008 [04:13<18:02,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 384/2008 [04:14<18:03,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 385/2008 [04:15<18:03,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 386/2008 [04:15<18:01,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 387/2008 [04:16<18:00,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 388/2008 [04:17<18:01,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 389/2008 [04:17<18:00,  1.50it/s]\u001b[A\n",
            "Iteration:  19% 390/2008 [04:18<18:03,  1.49it/s]\u001b[A\n",
            "Iteration:  19% 391/2008 [04:19<18:03,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 392/2008 [04:19<18:05,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 393/2008 [04:20<18:03,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 394/2008 [04:21<18:02,  1.49it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "\n",
            "Iteration:  20% 395/2008 [04:21<16:55,  1.59it/s]\u001b[A\n",
            "Iteration:  20% 396/2008 [04:22<17:11,  1.56it/s]\u001b[A\n",
            "Iteration:  20% 397/2008 [04:22<17:23,  1.54it/s]\u001b[A\n",
            "Iteration:  20% 398/2008 [04:23<17:32,  1.53it/s]\u001b[A\n",
            "Iteration:  20% 399/2008 [04:24<17:37,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 400/2008 [04:24<17:40,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 401/2008 [04:25<17:45,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 402/2008 [04:26<17:51,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 403/2008 [04:26<17:49,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 404/2008 [04:27<17:51,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 405/2008 [04:28<17:53,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 406/2008 [04:28<17:51,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 407/2008 [04:29<17:53,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 408/2008 [04:30<17:54,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 409/2008 [04:31<17:52,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 410/2008 [04:31<17:49,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 411/2008 [04:32<17:47,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 412/2008 [04:33<17:47,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 413/2008 [04:33<17:45,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 414/2008 [04:34<17:45,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 415/2008 [04:35<17:42,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 416/2008 [04:35<17:43,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 417/2008 [04:36<17:46,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 418/2008 [04:37<17:42,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 419/2008 [04:37<17:42,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 420/2008 [04:38<17:42,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 421/2008 [04:39<17:43,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 422/2008 [04:39<17:43,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 423/2008 [04:40<17:43,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 424/2008 [04:41<17:42,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 425/2008 [04:41<17:39,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 426/2008 [04:42<17:40,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 427/2008 [04:43<17:38,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 428/2008 [04:43<17:36,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 429/2008 [04:44<17:39,  1.49it/s]\u001b[A\n",
            "Iteration:  21% 430/2008 [04:45<17:35,  1.50it/s]\u001b[A\n",
            "Iteration:  21% 431/2008 [04:45<17:34,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 432/2008 [04:46<17:35,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 433/2008 [04:47<17:34,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 434/2008 [04:47<17:35,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 435/2008 [04:48<17:36,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 436/2008 [04:49<17:33,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 437/2008 [04:49<17:32,  1.49it/s]\u001b[A\n",
            "Iteration:  22% 438/2008 [04:50<17:29,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 439/2008 [04:51<17:29,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 440/2008 [04:51<17:27,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 441/2008 [04:52<17:28,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 442/2008 [04:53<17:25,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 443/2008 [04:53<17:24,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 444/2008 [04:54<17:24,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 445/2008 [04:55<17:22,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 446/2008 [04:55<17:19,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 447/2008 [04:56<17:19,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 448/2008 [04:57<17:20,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 449/2008 [04:57<17:19,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 450/2008 [04:58<17:19,  1.50it/s]\u001b[A\n",
            "Iteration:  22% 451/2008 [04:59<17:18,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 452/2008 [04:59<17:18,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 453/2008 [05:00<17:18,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 454/2008 [05:01<17:16,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 455/2008 [05:01<17:19,  1.49it/s]\u001b[A\n",
            "Iteration:  23% 456/2008 [05:02<17:17,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 457/2008 [05:03<17:15,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 458/2008 [05:03<17:15,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 459/2008 [05:04<17:15,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 460/2008 [05:05<17:17,  1.49it/s]\u001b[A\n",
            "Iteration:  23% 461/2008 [05:05<17:15,  1.49it/s]\u001b[A\n",
            "Iteration:  23% 462/2008 [05:06<17:13,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 463/2008 [05:07<17:13,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 464/2008 [05:07<17:13,  1.49it/s]\u001b[A\n",
            "Iteration:  23% 465/2008 [05:08<17:11,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 466/2008 [05:09<17:09,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 467/2008 [05:09<17:08,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 468/2008 [05:10<17:09,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 469/2008 [05:11<17:06,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 470/2008 [05:11<17:06,  1.50it/s]\u001b[A\n",
            "Iteration:  23% 471/2008 [05:12<17:07,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 472/2008 [05:13<17:06,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 473/2008 [05:13<17:06,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 474/2008 [05:14<17:06,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 475/2008 [05:15<17:10,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 476/2008 [05:15<17:05,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 477/2008 [05:16<17:05,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 478/2008 [05:17<17:01,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 479/2008 [05:17<17:01,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 480/2008 [05:18<17:02,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 481/2008 [05:19<17:00,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 482/2008 [05:19<17:01,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 483/2008 [05:20<17:01,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 484/2008 [05:21<16:59,  1.49it/s]\u001b[A\n",
            "Iteration:  24% 485/2008 [05:21<16:58,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 486/2008 [05:22<16:57,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 487/2008 [05:23<16:55,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 488/2008 [05:23<16:56,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 489/2008 [05:24<16:55,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 490/2008 [05:25<16:54,  1.50it/s]\u001b[A\n",
            "Iteration:  24% 491/2008 [05:25<16:53,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 492/2008 [05:26<16:52,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 493/2008 [05:27<16:50,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 494/2008 [05:27<16:50,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 495/2008 [05:28<16:49,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 496/2008 [05:29<16:48,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 497/2008 [05:29<16:48,  1.50it/s]\u001b[A\n",
            "Iteration:  25% 498/2008 [05:30<16:50,  1.49it/s]\u001b[A\n",
            "Iteration:  25% 499/2008 [05:31<16:49,  1.50it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "11/22/2020 13:17:25 - INFO - transformers.configuration_utils -   Configuration saved in ./ruGPT3medium_psy/checkpoint-500/config.json\n",
            "11/22/2020 13:17:39 - INFO - transformers.modeling_utils -   Model weights saved in ./ruGPT3medium_psy/checkpoint-500/pytorch_model.bin\n",
            "11/22/2020 13:17:40 - INFO - __main__ -   Saving model checkpoint to ./ruGPT3medium_psy/checkpoint-500\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "11/22/2020 13:18:52 - INFO - __main__ -   Saving optimizer and scheduler states to ./ruGPT3medium_psy/checkpoint-500\n",
            "\n",
            "Iteration:  25% 500/2008 [06:58<11:08:50, 26.61s/it]\u001b[A\n",
            "Iteration:  25% 501/2008 [06:59<7:53:02, 18.83s/it] \u001b[A\n",
            "Iteration:  25% 502/2008 [06:59<5:35:51, 13.38s/it]\u001b[A\n",
            "Iteration:  25% 503/2008 [07:00<3:59:52,  9.56s/it]\u001b[A\n",
            "Iteration:  25% 504/2008 [07:00<2:52:43,  6.89s/it]\u001b[A\n",
            "Iteration:  25% 505/2008 [07:01<2:05:45,  5.02s/it]\u001b[A\n",
            "Iteration:  25% 506/2008 [07:02<1:32:54,  3.71s/it]\u001b[A\n",
            "Iteration:  25% 507/2008 [07:02<1:09:55,  2.80s/it]\u001b[A\n",
            "Iteration:  25% 508/2008 [07:03<53:50,  2.15s/it]  \u001b[A\n",
            "Iteration:  25% 509/2008 [07:04<42:36,  1.71s/it]\u001b[A\n",
            "Iteration:  25% 510/2008 [07:04<34:45,  1.39s/it]\u001b[A\n",
            "Iteration:  25% 511/2008 [07:05<29:16,  1.17s/it]\u001b[A\n",
            "Iteration:  25% 512/2008 [07:06<25:28,  1.02s/it]\u001b[A\n",
            "Iteration:  26% 513/2008 [07:06<22:48,  1.09it/s]\u001b[A\n",
            "Iteration:  26% 514/2008 [07:07<20:58,  1.19it/s]\u001b[A\n",
            "Iteration:  26% 515/2008 [07:08<19:40,  1.26it/s]\u001b[A\n",
            "Iteration:  26% 516/2008 [07:08<18:43,  1.33it/s]\u001b[A\n",
            "Iteration:  26% 517/2008 [07:09<18:05,  1.37it/s]\u001b[A\n",
            "Iteration:  26% 518/2008 [07:10<17:39,  1.41it/s]\u001b[A\n",
            "Iteration:  26% 519/2008 [07:10<17:19,  1.43it/s]\u001b[A\n",
            "Iteration:  26% 520/2008 [07:11<17:06,  1.45it/s]\u001b[A\n",
            "Iteration:  26% 521/2008 [07:12<16:55,  1.46it/s]\u001b[A\n",
            "Iteration:  26% 522/2008 [07:12<16:48,  1.47it/s]\u001b[A\n",
            "Iteration:  26% 523/2008 [07:13<16:44,  1.48it/s]\u001b[A\n",
            "Iteration:  26% 524/2008 [07:14<16:39,  1.48it/s]\u001b[A\n",
            "Iteration:  26% 525/2008 [07:14<16:37,  1.49it/s]\u001b[A\n",
            "Iteration:  26% 526/2008 [07:15<16:36,  1.49it/s]\u001b[A\n",
            "Iteration:  26% 527/2008 [07:16<16:35,  1.49it/s]\u001b[A\n",
            "Iteration:  26% 528/2008 [07:16<16:36,  1.48it/s]\u001b[A\n",
            "Iteration:  26% 529/2008 [07:17<16:34,  1.49it/s]\u001b[A\n",
            "Iteration:  26% 530/2008 [07:18<16:37,  1.48it/s]\u001b[A\n",
            "Iteration:  26% 531/2008 [07:18<16:37,  1.48it/s]\u001b[A\n",
            "Iteration:  26% 532/2008 [07:19<16:38,  1.48it/s]\u001b[A\n",
            "Iteration:  27% 533/2008 [07:20<16:42,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 534/2008 [07:21<16:45,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 535/2008 [07:21<16:42,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 536/2008 [07:22<16:44,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 537/2008 [07:23<16:42,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 538/2008 [07:23<16:41,  1.47it/s]\u001b[A\n",
            "Iteration:  27% 539/2008 [07:24<16:46,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 540/2008 [07:25<16:42,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 541/2008 [07:25<16:42,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 542/2008 [07:26<16:42,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 543/2008 [07:27<16:43,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 544/2008 [07:27<16:45,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 545/2008 [07:28<16:46,  1.45it/s]\u001b[A\n",
            "Iteration:  27% 546/2008 [07:29<16:44,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 547/2008 [07:29<16:42,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 548/2008 [07:30<16:43,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 549/2008 [07:31<16:43,  1.45it/s]\u001b[A\n",
            "Iteration:  27% 550/2008 [07:32<16:41,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 551/2008 [07:32<16:38,  1.46it/s]\u001b[A\n",
            "Iteration:  27% 552/2008 [07:33<16:35,  1.46it/s]\u001b[A\n",
            "Iteration:  28% 553/2008 [07:34<16:32,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 554/2008 [07:34<16:34,  1.46it/s]\u001b[A\n",
            "Iteration:  28% 555/2008 [07:35<16:31,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 556/2008 [07:36<16:29,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 557/2008 [07:36<16:27,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 558/2008 [07:37<16:24,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 559/2008 [07:38<16:25,  1.47it/s]\u001b[A\n",
            "Iteration:  28% 560/2008 [07:38<16:20,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 561/2008 [07:39<16:20,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 562/2008 [07:40<16:18,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 563/2008 [07:40<16:14,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 564/2008 [07:41<16:15,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 565/2008 [07:42<16:13,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 566/2008 [07:42<16:11,  1.48it/s]\u001b[A\n",
            "Iteration:  28% 567/2008 [07:43<16:08,  1.49it/s]\u001b[A\n",
            "Iteration:  28% 568/2008 [07:44<16:09,  1.49it/s]\u001b[A\n",
            "Iteration:  28% 569/2008 [07:44<16:07,  1.49it/s]\u001b[A\n",
            "Iteration:  28% 570/2008 [07:45<16:05,  1.49it/s]\u001b[A\n",
            "Iteration:  28% 571/2008 [07:46<16:04,  1.49it/s]\u001b[A\n",
            "Iteration:  28% 572/2008 [07:46<16:05,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 573/2008 [07:47<16:04,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 574/2008 [07:48<16:04,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 575/2008 [07:48<16:02,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 576/2008 [07:49<15:58,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 577/2008 [07:50<15:55,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 578/2008 [07:50<15:55,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 579/2008 [07:51<15:56,  1.49it/s]\u001b[A\n",
            "Iteration:  29% 580/2008 [07:52<15:53,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 581/2008 [07:52<15:52,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 582/2008 [07:53<15:51,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 583/2008 [07:54<15:48,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 584/2008 [07:54<15:48,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 585/2008 [07:55<15:47,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 586/2008 [07:56<15:47,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 587/2008 [07:56<15:47,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 588/2008 [07:57<15:47,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 589/2008 [07:58<15:48,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 590/2008 [07:58<15:45,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 591/2008 [07:59<15:45,  1.50it/s]\u001b[A\n",
            "Iteration:  29% 592/2008 [08:00<15:43,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 593/2008 [08:00<15:44,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 594/2008 [08:01<15:42,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 595/2008 [08:02<15:40,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 596/2008 [08:02<15:40,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 597/2008 [08:03<15:38,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 598/2008 [08:04<15:36,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 599/2008 [08:04<15:32,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 600/2008 [08:05<15:33,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 601/2008 [08:06<15:34,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 602/2008 [08:06<15:33,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 603/2008 [08:07<15:31,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 604/2008 [08:08<15:31,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 605/2008 [08:08<15:29,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 606/2008 [08:09<15:28,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 607/2008 [08:10<15:26,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 608/2008 [08:10<15:26,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 609/2008 [08:11<15:28,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 610/2008 [08:12<15:26,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 611/2008 [08:12<15:24,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 612/2008 [08:13<15:24,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 613/2008 [08:14<15:21,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 614/2008 [08:14<15:23,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 615/2008 [08:15<15:19,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 616/2008 [08:16<15:18,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 617/2008 [08:16<15:17,  1.52it/s]\u001b[A\n",
            "Iteration:  31% 618/2008 [08:17<15:18,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 619/2008 [08:18<15:19,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 620/2008 [08:18<15:18,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 621/2008 [08:19<15:16,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 622/2008 [08:20<15:17,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 623/2008 [08:20<15:16,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 624/2008 [08:21<15:16,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 625/2008 [08:22<15:17,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 626/2008 [08:22<15:14,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 627/2008 [08:23<15:14,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 628/2008 [08:24<15:18,  1.50it/s]\u001b[A\n",
            "Iteration:  31% 629/2008 [08:24<15:17,  1.50it/s]\u001b[A\n",
            "Iteration:  31% 630/2008 [08:25<15:14,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 631/2008 [08:26<15:14,  1.51it/s]\u001b[A\n",
            "Iteration:  31% 632/2008 [08:26<15:12,  1.51it/s]\u001b[A\n",
            "Iteration:  32% 633/2008 [08:27<15:13,  1.51it/s]\u001b[A\n",
            "Iteration:  32% 634/2008 [08:28<15:12,  1.51it/s]\u001b[A\n",
            "Iteration:  32% 635/2008 [08:28<15:14,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 636/2008 [08:29<15:14,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 637/2008 [08:30<15:12,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 638/2008 [08:30<15:10,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 639/2008 [08:31<15:10,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 640/2008 [08:32<15:10,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 641/2008 [08:32<15:07,  1.51it/s]\u001b[A\n",
            "Iteration:  32% 642/2008 [08:33<15:10,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 643/2008 [08:34<15:12,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 644/2008 [08:34<15:11,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 645/2008 [08:35<15:10,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 646/2008 [08:36<15:07,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 647/2008 [08:36<15:08,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 648/2008 [08:37<15:09,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 649/2008 [08:38<15:11,  1.49it/s]\u001b[A\n",
            "Iteration:  32% 650/2008 [08:38<15:07,  1.50it/s]\u001b[A\n",
            "Iteration:  32% 651/2008 [08:39<15:09,  1.49it/s]\u001b[A\n",
            "Iteration:  32% 652/2008 [08:40<15:08,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 653/2008 [08:40<15:11,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 654/2008 [08:41<15:10,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 655/2008 [08:42<15:12,  1.48it/s]\u001b[A\n",
            "Iteration:  33% 656/2008 [08:42<15:08,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 657/2008 [08:43<15:09,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 658/2008 [08:44<15:09,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 659/2008 [08:44<15:06,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 660/2008 [08:45<15:08,  1.48it/s]\u001b[A\n",
            "Iteration:  33% 661/2008 [08:46<15:04,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 662/2008 [08:46<15:04,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 663/2008 [08:47<15:04,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 664/2008 [08:48<15:02,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 665/2008 [08:48<15:02,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 666/2008 [08:49<15:01,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 667/2008 [08:50<14:59,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 668/2008 [08:50<15:02,  1.48it/s]\u001b[A\n",
            "Iteration:  33% 669/2008 [08:51<15:00,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 670/2008 [08:52<15:00,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 671/2008 [08:52<14:59,  1.49it/s]\u001b[A\n",
            "Iteration:  33% 672/2008 [08:53<14:55,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 673/2008 [08:54<14:56,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 674/2008 [08:54<14:56,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 675/2008 [08:55<14:56,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 676/2008 [08:56<14:55,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 677/2008 [08:56<14:54,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 678/2008 [08:57<14:55,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 679/2008 [08:58<14:53,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 680/2008 [08:58<14:55,  1.48it/s]\u001b[A\n",
            "Iteration:  34% 681/2008 [08:59<14:53,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 682/2008 [09:00<14:53,  1.48it/s]\u001b[A\n",
            "Iteration:  34% 683/2008 [09:00<14:52,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 684/2008 [09:01<14:51,  1.48it/s]\u001b[A\n",
            "Iteration:  34% 685/2008 [09:02<14:49,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 686/2008 [09:02<14:48,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 687/2008 [09:03<14:45,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 688/2008 [09:04<14:44,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 689/2008 [09:04<14:43,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 690/2008 [09:05<14:42,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 691/2008 [09:06<14:42,  1.49it/s]\u001b[A\n",
            "Iteration:  34% 692/2008 [09:06<14:43,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 693/2008 [09:07<14:42,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 694/2008 [09:08<14:41,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 695/2008 [09:09<14:42,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 696/2008 [09:09<14:38,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 697/2008 [09:10<14:37,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 698/2008 [09:11<14:36,  1.50it/s]\u001b[A\n",
            "Iteration:  35% 699/2008 [09:11<14:37,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 700/2008 [09:12<14:38,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 701/2008 [09:13<14:37,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 702/2008 [09:13<14:38,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 703/2008 [09:14<14:38,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 704/2008 [09:15<14:38,  1.48it/s]\u001b[A\n",
            "Iteration:  35% 705/2008 [09:15<14:39,  1.48it/s]\u001b[A\n",
            "Iteration:  35% 706/2008 [09:16<14:36,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 707/2008 [09:17<14:34,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 708/2008 [09:17<14:30,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 709/2008 [09:18<14:30,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 710/2008 [09:19<14:27,  1.50it/s]\u001b[A\n",
            "Iteration:  35% 711/2008 [09:19<14:28,  1.49it/s]\u001b[A\n",
            "Iteration:  35% 712/2008 [09:20<14:25,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 713/2008 [09:21<14:23,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 714/2008 [09:21<14:23,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 715/2008 [09:22<14:22,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 716/2008 [09:23<14:22,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 717/2008 [09:23<14:23,  1.49it/s]\u001b[A\n",
            "Iteration:  36% 718/2008 [09:24<14:23,  1.49it/s]\u001b[A\n",
            "Iteration:  36% 719/2008 [09:25<14:22,  1.49it/s]\u001b[A\n",
            "Iteration:  36% 720/2008 [09:25<14:21,  1.49it/s]\u001b[A\n",
            "Iteration:  36% 721/2008 [09:26<14:20,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 722/2008 [09:27<14:18,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 723/2008 [09:27<14:16,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 724/2008 [09:28<14:19,  1.49it/s]\u001b[A\n",
            "Iteration:  36% 725/2008 [09:29<14:16,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 726/2008 [09:29<14:14,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 727/2008 [09:30<14:15,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 728/2008 [09:31<14:12,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 729/2008 [09:31<14:14,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 730/2008 [09:32<14:10,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 731/2008 [09:33<14:12,  1.50it/s]\u001b[A\n",
            "Iteration:  36% 732/2008 [09:33<14:10,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 733/2008 [09:34<14:11,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 734/2008 [09:35<14:12,  1.49it/s]\u001b[A\n",
            "Iteration:  37% 735/2008 [09:35<14:08,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 736/2008 [09:36<14:08,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 737/2008 [09:37<14:05,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 738/2008 [09:37<14:06,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 739/2008 [09:38<14:07,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 740/2008 [09:39<14:06,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 741/2008 [09:39<14:05,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 742/2008 [09:40<14:02,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 743/2008 [09:41<14:03,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 744/2008 [09:41<14:00,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 745/2008 [09:42<14:02,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 746/2008 [09:43<13:59,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 747/2008 [09:43<14:00,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 748/2008 [09:44<13:58,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 749/2008 [09:45<14:01,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 750/2008 [09:45<13:56,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 751/2008 [09:46<13:57,  1.50it/s]\u001b[A\n",
            "Iteration:  37% 752/2008 [09:47<13:57,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 753/2008 [09:47<13:54,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 754/2008 [09:48<13:54,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 755/2008 [09:49<13:53,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 756/2008 [09:49<13:52,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 757/2008 [09:50<13:51,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 758/2008 [09:51<13:50,  1.51it/s]\u001b[A\n",
            "Iteration:  38% 759/2008 [09:51<13:50,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 760/2008 [09:52<13:50,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 761/2008 [09:53<13:50,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 762/2008 [09:53<13:52,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 763/2008 [09:54<13:51,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 764/2008 [09:55<13:50,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 765/2008 [09:55<13:49,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 766/2008 [09:56<13:47,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 767/2008 [09:57<13:50,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 768/2008 [09:57<13:47,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 769/2008 [09:58<13:47,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 770/2008 [09:59<13:47,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 771/2008 [09:59<13:45,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 772/2008 [10:00<13:44,  1.50it/s]\u001b[A\n",
            "Iteration:  38% 773/2008 [10:01<13:44,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 774/2008 [10:01<13:43,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 775/2008 [10:02<13:41,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 776/2008 [10:03<13:41,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 777/2008 [10:03<13:44,  1.49it/s]\u001b[A\n",
            "Iteration:  39% 778/2008 [10:04<13:43,  1.49it/s]\u001b[A\n",
            "Iteration:  39% 779/2008 [10:05<13:41,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 780/2008 [10:05<13:39,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 781/2008 [10:06<13:40,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 782/2008 [10:07<13:39,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 783/2008 [10:07<13:39,  1.49it/s]\u001b[A\n",
            "Iteration:  39% 784/2008 [10:08<13:37,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 785/2008 [10:09<13:36,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 786/2008 [10:09<13:34,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 787/2008 [10:10<13:34,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 788/2008 [10:11<13:34,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 789/2008 [10:11<13:32,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 790/2008 [10:12<13:33,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 791/2008 [10:13<13:33,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 792/2008 [10:13<13:30,  1.50it/s]\u001b[A\n",
            "Iteration:  39% 793/2008 [10:14<13:29,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 794/2008 [10:15<13:28,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 795/2008 [10:15<13:27,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 796/2008 [10:16<13:29,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 797/2008 [10:17<13:27,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 798/2008 [10:17<13:26,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 799/2008 [10:18<13:28,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 800/2008 [10:19<13:26,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 801/2008 [10:19<13:25,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 802/2008 [10:20<13:23,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 803/2008 [10:21<13:22,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 804/2008 [10:21<13:20,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 805/2008 [10:22<13:21,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 806/2008 [10:23<13:22,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 807/2008 [10:23<13:22,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 808/2008 [10:24<13:23,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 809/2008 [10:25<13:24,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 810/2008 [10:25<13:22,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 811/2008 [10:26<13:22,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 812/2008 [10:27<13:20,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 813/2008 [10:27<13:18,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 814/2008 [10:28<13:17,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 815/2008 [10:29<13:15,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 816/2008 [10:29<13:15,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 817/2008 [10:30<13:16,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 818/2008 [10:31<13:15,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 819/2008 [10:31<13:13,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 820/2008 [10:32<13:13,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 821/2008 [10:33<13:12,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 822/2008 [10:33<13:10,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 823/2008 [10:34<13:10,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 824/2008 [10:35<13:08,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 825/2008 [10:35<13:08,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 826/2008 [10:36<13:08,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 827/2008 [10:37<13:09,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 828/2008 [10:37<13:07,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 829/2008 [10:38<13:08,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 830/2008 [10:39<13:05,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 831/2008 [10:39<13:05,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 832/2008 [10:40<13:05,  1.50it/s]\u001b[A\n",
            "Iteration:  41% 833/2008 [10:41<13:03,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 834/2008 [10:41<13:03,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 835/2008 [10:42<13:02,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 836/2008 [10:43<13:03,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 837/2008 [10:43<13:01,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 838/2008 [10:44<13:01,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 839/2008 [10:45<12:59,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 840/2008 [10:45<12:59,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 841/2008 [10:46<12:59,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 842/2008 [10:47<12:58,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 843/2008 [10:47<12:58,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 844/2008 [10:48<12:56,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 845/2008 [10:49<12:57,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 846/2008 [10:49<12:57,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 847/2008 [10:50<12:56,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 848/2008 [10:51<12:54,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 849/2008 [10:51<12:53,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 850/2008 [10:52<12:52,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 851/2008 [10:53<12:51,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 852/2008 [10:53<12:51,  1.50it/s]\u001b[A\n",
            "Iteration:  42% 853/2008 [10:54<12:49,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 854/2008 [10:55<12:51,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 855/2008 [10:55<12:49,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 856/2008 [10:56<12:49,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 857/2008 [10:57<12:48,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 858/2008 [10:57<12:47,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 859/2008 [10:58<12:46,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 860/2008 [10:59<12:46,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 861/2008 [10:59<12:43,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 862/2008 [11:00<12:43,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 863/2008 [11:01<12:44,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 864/2008 [11:01<12:43,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 865/2008 [11:02<12:43,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 866/2008 [11:03<12:42,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 867/2008 [11:03<12:41,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 868/2008 [11:04<12:41,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 869/2008 [11:05<12:41,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 870/2008 [11:05<12:38,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 871/2008 [11:06<12:38,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 872/2008 [11:07<12:37,  1.50it/s]\u001b[A\n",
            "Iteration:  43% 873/2008 [11:07<12:37,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 874/2008 [11:08<12:36,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 875/2008 [11:09<12:38,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 876/2008 [11:09<12:35,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 877/2008 [11:10<12:36,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 878/2008 [11:11<12:34,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 879/2008 [11:11<12:33,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 880/2008 [11:12<12:34,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 881/2008 [11:13<12:32,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 882/2008 [11:13<12:33,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 883/2008 [11:14<12:32,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 884/2008 [11:15<12:32,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 885/2008 [11:15<12:30,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 886/2008 [11:16<12:31,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 887/2008 [11:17<12:30,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 888/2008 [11:17<12:28,  1.50it/s]\u001b[A\n",
            "Iteration:  44% 889/2008 [11:18<12:29,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 890/2008 [11:19<12:32,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 891/2008 [11:19<12:30,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 892/2008 [11:20<12:28,  1.49it/s]\u001b[A\n",
            "Iteration:  44% 893/2008 [11:21<12:26,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 894/2008 [11:21<12:26,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 895/2008 [11:22<12:24,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 896/2008 [11:23<12:26,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 897/2008 [11:23<12:24,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 898/2008 [11:24<12:23,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 899/2008 [11:25<12:22,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 900/2008 [11:25<12:20,  1.50it/s]\u001b[A\n",
            "Iteration:  45% 901/2008 [11:26<12:18,  1.50it/s]\u001b[A\n",
            "Iteration:  45% 902/2008 [11:27<12:21,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 903/2008 [11:27<12:22,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 904/2008 [11:28<12:21,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 905/2008 [11:29<12:20,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 906/2008 [11:29<12:17,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 907/2008 [11:30<12:16,  1.50it/s]\u001b[A\n",
            "Iteration:  45% 908/2008 [11:31<12:13,  1.50it/s]\u001b[A\n",
            "Iteration:  45% 909/2008 [11:31<12:14,  1.50it/s]\u001b[A\n",
            "Iteration:  45% 910/2008 [11:32<12:14,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 911/2008 [11:33<12:15,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 912/2008 [11:33<12:14,  1.49it/s]\u001b[A\n",
            "Iteration:  45% 913/2008 [11:34<12:12,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 914/2008 [11:35<12:11,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 915/2008 [11:35<12:10,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 916/2008 [11:36<12:10,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 917/2008 [11:37<12:09,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 918/2008 [11:37<12:09,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 919/2008 [11:38<12:07,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 920/2008 [11:39<12:08,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 921/2008 [11:39<12:06,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 922/2008 [11:40<12:06,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 923/2008 [11:41<12:04,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 924/2008 [11:41<12:06,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 925/2008 [11:42<12:03,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 926/2008 [11:43<12:04,  1.49it/s]\u001b[A\n",
            "Iteration:  46% 927/2008 [11:43<12:02,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 928/2008 [11:44<11:59,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 929/2008 [11:45<11:58,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 930/2008 [11:45<11:58,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 931/2008 [11:46<11:56,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 932/2008 [11:47<11:56,  1.50it/s]\u001b[A\n",
            "Iteration:  46% 933/2008 [11:47<11:56,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 934/2008 [11:48<11:55,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 935/2008 [11:49<11:54,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 936/2008 [11:49<11:53,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 937/2008 [11:50<11:53,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 938/2008 [11:51<11:54,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 939/2008 [11:51<11:53,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 940/2008 [11:52<11:52,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 941/2008 [11:53<11:50,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 942/2008 [11:53<11:50,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 943/2008 [11:54<11:51,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 944/2008 [11:55<11:48,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 945/2008 [11:55<11:47,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 946/2008 [11:56<11:47,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 947/2008 [11:57<11:47,  1.50it/s]\u001b[A\n",
            "Iteration:  47% 948/2008 [11:57<11:51,  1.49it/s]\u001b[A\n",
            "Iteration:  47% 949/2008 [11:58<11:50,  1.49it/s]\u001b[A\n",
            "Iteration:  47% 950/2008 [11:59<11:49,  1.49it/s]\u001b[A\n",
            "Iteration:  47% 951/2008 [11:59<11:47,  1.49it/s]\u001b[A\n",
            "Iteration:  47% 952/2008 [12:00<11:48,  1.49it/s]\u001b[A\n",
            "Iteration:  47% 953/2008 [12:01<11:47,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 954/2008 [12:02<11:46,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 955/2008 [12:02<11:45,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 956/2008 [12:03<11:42,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 957/2008 [12:04<11:42,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 958/2008 [12:04<11:40,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 959/2008 [12:05<11:39,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 960/2008 [12:06<11:39,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 961/2008 [12:06<11:39,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 962/2008 [12:07<11:38,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 963/2008 [12:08<11:36,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 964/2008 [12:08<11:36,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 965/2008 [12:09<11:35,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 966/2008 [12:10<11:35,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 967/2008 [12:10<11:37,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 968/2008 [12:11<11:37,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 969/2008 [12:12<11:37,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 970/2008 [12:12<11:35,  1.49it/s]\u001b[A\n",
            "Iteration:  48% 971/2008 [12:13<11:33,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 972/2008 [12:14<11:31,  1.50it/s]\u001b[A\n",
            "Iteration:  48% 973/2008 [12:14<11:31,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 974/2008 [12:15<11:30,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 975/2008 [12:16<11:30,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 976/2008 [12:16<11:29,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 977/2008 [12:17<11:28,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 978/2008 [12:18<11:28,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 979/2008 [12:18<11:25,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 980/2008 [12:19<11:25,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 981/2008 [12:20<11:24,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 982/2008 [12:20<11:23,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 983/2008 [12:21<11:23,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 984/2008 [12:22<11:23,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 985/2008 [12:22<11:22,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 986/2008 [12:23<11:22,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 987/2008 [12:24<11:21,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 988/2008 [12:24<11:21,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 989/2008 [12:25<11:20,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 990/2008 [12:26<11:19,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 991/2008 [12:26<11:19,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 992/2008 [12:27<11:17,  1.50it/s]\u001b[A\n",
            "Iteration:  49% 993/2008 [12:28<11:18,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 994/2008 [12:28<11:17,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 995/2008 [12:29<11:16,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 996/2008 [12:30<11:14,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 997/2008 [12:30<11:13,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 998/2008 [12:31<11:14,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 999/2008 [12:32<11:12,  1.50it/s]\u001b[A11/22/2020 13:24:26 - INFO - transformers.configuration_utils -   Configuration saved in ./ruGPT3medium_psy/checkpoint-1000/config.json\n",
            "11/22/2020 13:24:40 - INFO - transformers.modeling_utils -   Model weights saved in ./ruGPT3medium_psy/checkpoint-1000/pytorch_model.bin\n",
            "11/22/2020 13:24:40 - INFO - __main__ -   Saving model checkpoint to ./ruGPT3medium_psy/checkpoint-1000\n",
            "11/22/2020 13:25:52 - INFO - __main__ -   Saving optimizer and scheduler states to ./ruGPT3medium_psy/checkpoint-1000\n",
            "\n",
            "Iteration:  50% 1000/2008 [13:59<7:27:20, 26.63s/it]\u001b[A\n",
            "Iteration:  50% 1001/2008 [13:59<5:16:19, 18.85s/it]\u001b[A\n",
            "Iteration:  50% 1002/2008 [14:00<3:44:31, 13.39s/it]\u001b[A\n",
            "Iteration:  50% 1003/2008 [14:01<2:40:22,  9.57s/it]\u001b[A\n",
            "Iteration:  50% 1004/2008 [14:01<1:55:30,  6.90s/it]\u001b[A\n",
            "Iteration:  50% 1005/2008 [14:02<1:24:05,  5.03s/it]\u001b[A\n",
            "Iteration:  50% 1006/2008 [14:03<1:02:07,  3.72s/it]\u001b[A\n",
            "Iteration:  50% 1007/2008 [14:03<46:48,  2.81s/it]  \u001b[A\n",
            "Iteration:  50% 1008/2008 [14:04<36:04,  2.16s/it]\u001b[A\n",
            "Iteration:  50% 1009/2008 [14:05<28:33,  1.72s/it]\u001b[A\n",
            "Iteration:  50% 1010/2008 [14:05<23:18,  1.40s/it]\u001b[A\n",
            "Iteration:  50% 1011/2008 [14:06<19:37,  1.18s/it]\u001b[A\n",
            "Iteration:  50% 1012/2008 [14:07<17:04,  1.03s/it]\u001b[A\n",
            "Iteration:  50% 1013/2008 [14:07<15:16,  1.09it/s]\u001b[A\n",
            "Iteration:  50% 1014/2008 [14:08<14:00,  1.18it/s]\u001b[A\n",
            "Iteration:  51% 1015/2008 [14:09<13:08,  1.26it/s]\u001b[A\n",
            "Iteration:  51% 1016/2008 [14:09<12:31,  1.32it/s]\u001b[A\n",
            "Iteration:  51% 1017/2008 [14:10<12:05,  1.37it/s]\u001b[A\n",
            "Iteration:  51% 1018/2008 [14:11<11:49,  1.40it/s]\u001b[A\n",
            "Iteration:  51% 1019/2008 [14:11<11:36,  1.42it/s]\u001b[A\n",
            "Iteration:  51% 1020/2008 [14:12<11:29,  1.43it/s]\u001b[A\n",
            "Iteration:  51% 1021/2008 [14:13<11:23,  1.44it/s]\u001b[A\n",
            "Iteration:  51% 1022/2008 [14:14<11:22,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1023/2008 [14:14<11:19,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1024/2008 [14:15<11:18,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1025/2008 [14:16<11:17,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1026/2008 [14:16<11:14,  1.46it/s]\u001b[A\n",
            "Iteration:  51% 1027/2008 [14:17<11:12,  1.46it/s]\u001b[A\n",
            "Iteration:  51% 1028/2008 [14:18<11:14,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1029/2008 [14:18<11:13,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1030/2008 [14:19<11:11,  1.46it/s]\u001b[A\n",
            "Iteration:  51% 1031/2008 [14:20<11:11,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1032/2008 [14:20<11:10,  1.46it/s]\u001b[A\n",
            "Iteration:  51% 1033/2008 [14:21<11:11,  1.45it/s]\u001b[A\n",
            "Iteration:  51% 1034/2008 [14:22<11:10,  1.45it/s]\u001b[A\n",
            "Iteration:  52% 1035/2008 [14:22<11:08,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1036/2008 [14:23<11:08,  1.45it/s]\u001b[A\n",
            "Iteration:  52% 1037/2008 [14:24<11:08,  1.45it/s]\u001b[A\n",
            "Iteration:  52% 1038/2008 [14:25<11:07,  1.45it/s]\u001b[A\n",
            "Iteration:  52% 1039/2008 [14:25<11:05,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1040/2008 [14:26<11:04,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1041/2008 [14:27<11:01,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1042/2008 [14:27<11:01,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1043/2008 [14:28<10:58,  1.46it/s]\u001b[A\n",
            "Iteration:  52% 1044/2008 [14:29<10:56,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1045/2008 [14:29<10:55,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1046/2008 [14:30<10:54,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1047/2008 [14:31<10:52,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1048/2008 [14:31<10:52,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1049/2008 [14:32<10:50,  1.47it/s]\u001b[A\n",
            "Iteration:  52% 1050/2008 [14:33<10:49,  1.48it/s]\u001b[A\n",
            "Iteration:  52% 1051/2008 [14:33<10:46,  1.48it/s]\u001b[A\n",
            "Iteration:  52% 1052/2008 [14:34<10:44,  1.48it/s]\u001b[A\n",
            "Iteration:  52% 1053/2008 [14:35<10:43,  1.48it/s]\u001b[A\n",
            "Iteration:  52% 1054/2008 [14:35<10:44,  1.48it/s]\u001b[A\n",
            "Iteration:  53% 1055/2008 [14:36<10:42,  1.48it/s]\u001b[A\n",
            "Iteration:  53% 1056/2008 [14:37<10:40,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1057/2008 [14:37<10:40,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1058/2008 [14:38<10:39,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1059/2008 [14:39<10:38,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1060/2008 [14:39<10:38,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1061/2008 [14:40<10:37,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1062/2008 [14:41<10:35,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1063/2008 [14:41<10:33,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1064/2008 [14:42<10:33,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1065/2008 [14:43<10:33,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1066/2008 [14:43<10:33,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1067/2008 [14:44<10:31,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1068/2008 [14:45<10:30,  1.49it/s]\u001b[A\n",
            "Iteration:  53% 1069/2008 [14:45<10:27,  1.50it/s]\u001b[A\n",
            "Iteration:  53% 1070/2008 [14:46<10:24,  1.50it/s]\u001b[A\n",
            "Iteration:  53% 1071/2008 [14:47<10:24,  1.50it/s]\u001b[A\n",
            "Iteration:  53% 1072/2008 [14:47<10:24,  1.50it/s]\u001b[A\n",
            "Iteration:  53% 1073/2008 [14:48<10:23,  1.50it/s]\u001b[A\n",
            "Iteration:  53% 1074/2008 [14:49<10:23,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1075/2008 [14:49<10:21,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1076/2008 [14:50<10:20,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1077/2008 [14:51<10:19,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1078/2008 [14:51<10:21,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1079/2008 [14:52<10:19,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1080/2008 [14:53<10:18,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1081/2008 [14:53<10:17,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1082/2008 [14:54<10:14,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1083/2008 [14:55<10:13,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1084/2008 [14:55<10:12,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1085/2008 [14:56<10:12,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1086/2008 [14:57<10:11,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1087/2008 [14:57<10:10,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1088/2008 [14:58<10:09,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1089/2008 [14:59<10:09,  1.51it/s]\u001b[A\n",
            "Iteration:  54% 1090/2008 [14:59<10:10,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1091/2008 [15:00<10:09,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1092/2008 [15:01<10:10,  1.50it/s]\u001b[A\n",
            "Iteration:  54% 1093/2008 [15:01<10:12,  1.49it/s]\u001b[A\n",
            "Iteration:  54% 1094/2008 [15:02<10:09,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1095/2008 [15:03<10:08,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1096/2008 [15:03<10:08,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1097/2008 [15:04<10:07,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1098/2008 [15:05<10:05,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1099/2008 [15:05<10:03,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1100/2008 [15:06<10:03,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1101/2008 [15:07<10:01,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1102/2008 [15:07<10:00,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1103/2008 [15:08<09:59,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1104/2008 [15:09<09:58,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1105/2008 [15:09<09:58,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1106/2008 [15:10<09:56,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1107/2008 [15:11<09:57,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1108/2008 [15:11<09:57,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1109/2008 [15:12<09:56,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1110/2008 [15:13<09:55,  1.51it/s]\u001b[A\n",
            "Iteration:  55% 1111/2008 [15:13<09:56,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1112/2008 [15:14<09:56,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1113/2008 [15:15<09:56,  1.50it/s]\u001b[A\n",
            "Iteration:  55% 1114/2008 [15:15<09:55,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1115/2008 [15:16<09:53,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1116/2008 [15:17<09:52,  1.51it/s]\u001b[A\n",
            "Iteration:  56% 1117/2008 [15:17<09:51,  1.51it/s]\u001b[A\n",
            "Iteration:  56% 1118/2008 [15:18<09:52,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1119/2008 [15:19<09:50,  1.51it/s]\u001b[A\n",
            "Iteration:  56% 1120/2008 [15:19<09:53,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1121/2008 [15:20<09:52,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1122/2008 [15:21<09:51,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1123/2008 [15:21<09:49,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1124/2008 [15:22<09:50,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1125/2008 [15:23<09:50,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1126/2008 [15:23<09:50,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1127/2008 [15:24<09:50,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1128/2008 [15:25<09:48,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1129/2008 [15:25<09:48,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1130/2008 [15:26<09:48,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1131/2008 [15:27<09:46,  1.50it/s]\u001b[A\n",
            "Iteration:  56% 1132/2008 [15:27<09:49,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1133/2008 [15:28<09:47,  1.49it/s]\u001b[A\n",
            "Iteration:  56% 1134/2008 [15:29<09:46,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1135/2008 [15:29<09:46,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1136/2008 [15:30<09:44,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1137/2008 [15:31<09:43,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1138/2008 [15:31<09:43,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1139/2008 [15:32<09:44,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1140/2008 [15:33<09:42,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1141/2008 [15:33<09:42,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1142/2008 [15:34<09:42,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1143/2008 [15:35<09:41,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1144/2008 [15:35<09:42,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1145/2008 [15:36<09:41,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1146/2008 [15:37<09:39,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1147/2008 [15:37<09:39,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1148/2008 [15:38<09:39,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1149/2008 [15:39<09:36,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1150/2008 [15:40<09:39,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1151/2008 [15:40<09:35,  1.49it/s]\u001b[A\n",
            "Iteration:  57% 1152/2008 [15:41<09:36,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1153/2008 [15:42<09:35,  1.48it/s]\u001b[A\n",
            "Iteration:  57% 1154/2008 [15:42<09:33,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1155/2008 [15:43<09:32,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1156/2008 [15:44<09:32,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1157/2008 [15:44<09:31,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1158/2008 [15:45<09:29,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1159/2008 [15:46<09:30,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1160/2008 [15:46<09:28,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1161/2008 [15:47<09:29,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1162/2008 [15:48<09:28,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1163/2008 [15:48<09:28,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1164/2008 [15:49<09:27,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1165/2008 [15:50<09:26,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1166/2008 [15:50<09:24,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1167/2008 [15:51<09:23,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1168/2008 [15:52<09:23,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1169/2008 [15:52<09:22,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1170/2008 [15:53<09:22,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1171/2008 [15:54<09:20,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1172/2008 [15:54<09:20,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1173/2008 [15:55<09:19,  1.49it/s]\u001b[A\n",
            "Iteration:  58% 1174/2008 [15:56<09:19,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1175/2008 [15:56<09:18,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1176/2008 [15:57<09:18,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1177/2008 [15:58<09:19,  1.48it/s]\u001b[A\n",
            "Iteration:  59% 1178/2008 [15:58<09:17,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1179/2008 [15:59<09:16,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1180/2008 [16:00<09:14,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1181/2008 [16:00<09:13,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1182/2008 [16:01<09:12,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1183/2008 [16:02<09:12,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1184/2008 [16:02<09:11,  1.50it/s]\u001b[A\n",
            "Iteration:  59% 1185/2008 [16:03<09:10,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1186/2008 [16:04<09:11,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1187/2008 [16:04<09:10,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1188/2008 [16:05<09:09,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1189/2008 [16:06<09:07,  1.50it/s]\u001b[A\n",
            "Iteration:  59% 1190/2008 [16:06<09:07,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1191/2008 [16:07<09:07,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1192/2008 [16:08<09:06,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1193/2008 [16:08<09:05,  1.49it/s]\u001b[A\n",
            "Iteration:  59% 1194/2008 [16:09<09:04,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1195/2008 [16:10<09:04,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1196/2008 [16:10<09:02,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 1197/2008 [16:11<09:05,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1198/2008 [16:12<09:02,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1199/2008 [16:12<09:02,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1200/2008 [16:13<09:02,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1201/2008 [16:14<09:01,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1202/2008 [16:14<09:02,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1203/2008 [16:15<09:02,  1.48it/s]\u001b[A\n",
            "Iteration:  60% 1204/2008 [16:16<08:59,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1205/2008 [16:16<08:59,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1206/2008 [16:17<08:56,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1207/2008 [16:18<08:58,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1208/2008 [16:18<08:55,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1209/2008 [16:19<08:54,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1210/2008 [16:20<08:53,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 1211/2008 [16:20<08:52,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 1212/2008 [16:21<08:53,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 1213/2008 [16:22<08:51,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 1214/2008 [16:22<08:51,  1.49it/s]\u001b[A\n",
            "Iteration:  61% 1215/2008 [16:23<08:49,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1216/2008 [16:24<08:50,  1.49it/s]\u001b[A\n",
            "Iteration:  61% 1217/2008 [16:24<08:48,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1218/2008 [16:25<08:47,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1219/2008 [16:26<08:45,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1220/2008 [16:26<08:45,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1221/2008 [16:27<08:46,  1.49it/s]\u001b[A\n",
            "Iteration:  61% 1222/2008 [16:28<08:45,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1223/2008 [16:28<08:44,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1224/2008 [16:29<08:42,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1225/2008 [16:30<08:41,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1226/2008 [16:30<08:41,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1227/2008 [16:31<08:40,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1228/2008 [16:32<08:40,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1229/2008 [16:32<08:41,  1.49it/s]\u001b[A\n",
            "Iteration:  61% 1230/2008 [16:33<08:39,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1231/2008 [16:34<08:39,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1232/2008 [16:34<08:37,  1.50it/s]\u001b[A\n",
            "Iteration:  61% 1233/2008 [16:35<08:39,  1.49it/s]\u001b[A\n",
            "Iteration:  61% 1234/2008 [16:36<08:38,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1235/2008 [16:36<08:37,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1236/2008 [16:37<08:37,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1237/2008 [16:38<08:37,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1238/2008 [16:38<08:34,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1239/2008 [16:39<08:33,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1240/2008 [16:40<08:33,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1241/2008 [16:40<08:32,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1242/2008 [16:41<08:31,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1243/2008 [16:42<08:31,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1244/2008 [16:42<08:30,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1245/2008 [16:43<08:29,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1246/2008 [16:44<08:28,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1247/2008 [16:44<08:28,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1248/2008 [16:45<08:27,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1249/2008 [16:46<08:27,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1250/2008 [16:46<08:28,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1251/2008 [16:47<08:25,  1.50it/s]\u001b[A\n",
            "Iteration:  62% 1252/2008 [16:48<08:26,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1253/2008 [16:48<08:25,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1254/2008 [16:49<08:25,  1.49it/s]\u001b[A\n",
            "Iteration:  62% 1255/2008 [16:50<08:23,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1256/2008 [16:50<08:23,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1257/2008 [16:51<08:21,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1258/2008 [16:52<08:21,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1259/2008 [16:53<08:20,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1260/2008 [16:53<08:19,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1261/2008 [16:54<08:18,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1262/2008 [16:55<08:17,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1263/2008 [16:55<08:16,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1264/2008 [16:56<08:15,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1265/2008 [16:57<08:15,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1266/2008 [16:57<08:15,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1267/2008 [16:58<08:15,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1268/2008 [16:59<08:15,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1269/2008 [16:59<08:15,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1270/2008 [17:00<08:14,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1271/2008 [17:01<08:14,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1272/2008 [17:01<08:12,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1273/2008 [17:02<08:12,  1.49it/s]\u001b[A\n",
            "Iteration:  63% 1274/2008 [17:03<08:10,  1.50it/s]\u001b[A\n",
            "Iteration:  63% 1275/2008 [17:03<08:11,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1276/2008 [17:04<08:12,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1277/2008 [17:05<08:10,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1278/2008 [17:05<08:10,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1279/2008 [17:06<08:10,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1280/2008 [17:07<08:08,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1281/2008 [17:07<08:06,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1282/2008 [17:08<08:05,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1283/2008 [17:09<08:04,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1284/2008 [17:09<08:03,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1285/2008 [17:10<08:03,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1286/2008 [17:11<08:03,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1287/2008 [17:11<08:01,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1288/2008 [17:12<08:01,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1289/2008 [17:13<07:59,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1290/2008 [17:13<07:59,  1.50it/s]\u001b[A\n",
            "Iteration:  64% 1291/2008 [17:14<08:00,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1292/2008 [17:15<08:00,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1293/2008 [17:15<07:59,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1294/2008 [17:16<07:59,  1.49it/s]\u001b[A\n",
            "Iteration:  64% 1295/2008 [17:17<07:57,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1296/2008 [17:17<07:58,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1297/2008 [17:18<07:59,  1.48it/s]\u001b[A\n",
            "Iteration:  65% 1298/2008 [17:19<07:56,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1299/2008 [17:19<07:55,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1300/2008 [17:20<07:53,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1301/2008 [17:21<07:52,  1.50it/s]\u001b[A\n",
            "Iteration:  65% 1302/2008 [17:21<07:53,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1303/2008 [17:22<07:51,  1.50it/s]\u001b[A\n",
            "Iteration:  65% 1304/2008 [17:23<07:52,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1305/2008 [17:23<07:51,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1306/2008 [17:24<07:51,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1307/2008 [17:25<07:49,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1308/2008 [17:25<07:49,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1309/2008 [17:26<07:47,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1310/2008 [17:27<07:47,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1311/2008 [17:27<07:46,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1312/2008 [17:28<07:47,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1313/2008 [17:29<07:45,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1314/2008 [17:29<07:44,  1.49it/s]\u001b[A\n",
            "Iteration:  65% 1315/2008 [17:30<07:46,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1316/2008 [17:31<07:43,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1317/2008 [17:31<07:44,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1318/2008 [17:32<07:42,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1319/2008 [17:33<07:41,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1320/2008 [17:33<07:42,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1321/2008 [17:34<07:41,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1322/2008 [17:35<07:40,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1323/2008 [17:35<07:39,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1324/2008 [17:36<07:40,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1325/2008 [17:37<07:38,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1326/2008 [17:37<07:36,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1327/2008 [17:38<07:36,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1328/2008 [17:39<07:35,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1329/2008 [17:39<07:36,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1330/2008 [17:40<07:34,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1331/2008 [17:41<07:32,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1332/2008 [17:41<07:34,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1333/2008 [17:42<07:33,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1334/2008 [17:43<07:32,  1.49it/s]\u001b[A\n",
            "Iteration:  66% 1335/2008 [17:43<07:31,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1336/2008 [17:44<07:30,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1337/2008 [17:45<07:29,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1338/2008 [17:45<07:30,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1339/2008 [17:46<07:29,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1340/2008 [17:47<07:29,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1341/2008 [17:47<07:28,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1342/2008 [17:48<07:28,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1343/2008 [17:49<07:26,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1344/2008 [17:49<07:25,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1345/2008 [17:50<07:24,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1346/2008 [17:51<07:23,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1347/2008 [17:51<07:22,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1348/2008 [17:52<07:22,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1349/2008 [17:53<07:21,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1350/2008 [17:53<07:20,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1351/2008 [17:54<07:20,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1352/2008 [17:55<07:18,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1353/2008 [17:56<07:18,  1.49it/s]\u001b[A\n",
            "Iteration:  67% 1354/2008 [17:56<07:17,  1.50it/s]\u001b[A\n",
            "Iteration:  67% 1355/2008 [17:57<07:17,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1356/2008 [17:58<07:17,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1357/2008 [17:58<07:16,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1358/2008 [17:59<07:16,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1359/2008 [18:00<07:14,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1360/2008 [18:00<07:14,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1361/2008 [18:01<07:13,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1362/2008 [18:02<07:12,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1363/2008 [18:02<07:11,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1364/2008 [18:03<07:11,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1365/2008 [18:04<07:11,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1366/2008 [18:04<07:10,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1367/2008 [18:05<07:09,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1368/2008 [18:06<07:08,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1369/2008 [18:06<07:08,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1370/2008 [18:07<07:09,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1371/2008 [18:08<07:07,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1372/2008 [18:08<07:06,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1373/2008 [18:09<07:05,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1374/2008 [18:10<07:06,  1.49it/s]\u001b[A\n",
            "Iteration:  68% 1375/2008 [18:10<07:05,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1376/2008 [18:11<07:04,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1377/2008 [18:12<07:02,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1378/2008 [18:12<07:03,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1379/2008 [18:13<07:01,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1380/2008 [18:14<07:02,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1381/2008 [18:14<07:00,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1382/2008 [18:15<07:00,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1383/2008 [18:16<07:00,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1384/2008 [18:16<06:58,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1385/2008 [18:17<06:57,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1386/2008 [18:18<06:58,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1387/2008 [18:18<06:57,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1388/2008 [18:19<06:56,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1389/2008 [18:20<06:56,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1390/2008 [18:20<06:56,  1.48it/s]\u001b[A\n",
            "Iteration:  69% 1391/2008 [18:21<06:55,  1.48it/s]\u001b[A\n",
            "Iteration:  69% 1392/2008 [18:22<06:55,  1.48it/s]\u001b[A\n",
            "Iteration:  69% 1393/2008 [18:22<06:54,  1.48it/s]\u001b[A\n",
            "Iteration:  69% 1394/2008 [18:23<06:52,  1.49it/s]\u001b[A\n",
            "Iteration:  69% 1395/2008 [18:24<06:53,  1.48it/s]\u001b[A\n",
            "Iteration:  70% 1396/2008 [18:24<06:51,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1397/2008 [18:25<06:50,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1398/2008 [18:26<06:49,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1399/2008 [18:26<06:48,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1400/2008 [18:27<06:49,  1.48it/s]\u001b[A\n",
            "Iteration:  70% 1401/2008 [18:28<06:47,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1402/2008 [18:28<06:47,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1403/2008 [18:29<06:46,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1404/2008 [18:30<06:45,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1405/2008 [18:30<06:44,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1406/2008 [18:31<06:42,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1407/2008 [18:32<06:41,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 1408/2008 [18:32<06:41,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1409/2008 [18:33<06:40,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 1410/2008 [18:34<06:41,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1411/2008 [18:34<06:40,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1412/2008 [18:35<06:39,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1413/2008 [18:36<06:38,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1414/2008 [18:36<06:38,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 1415/2008 [18:37<06:37,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1416/2008 [18:38<06:37,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1417/2008 [18:38<06:36,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1418/2008 [18:39<06:35,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1419/2008 [18:40<06:34,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1420/2008 [18:40<06:36,  1.48it/s]\u001b[A\n",
            "Iteration:  71% 1421/2008 [18:41<06:33,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1422/2008 [18:42<06:34,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1423/2008 [18:42<06:33,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1424/2008 [18:43<06:31,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1425/2008 [18:44<06:32,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1426/2008 [18:45<06:30,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1427/2008 [18:45<06:29,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1428/2008 [18:46<06:28,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1429/2008 [18:47<06:27,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1430/2008 [18:47<06:27,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1431/2008 [18:48<06:27,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1432/2008 [18:49<06:26,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1433/2008 [18:49<06:24,  1.49it/s]\u001b[A\n",
            "Iteration:  71% 1434/2008 [18:50<06:23,  1.50it/s]\u001b[A\n",
            "Iteration:  71% 1435/2008 [18:51<06:23,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1436/2008 [18:51<06:22,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1437/2008 [18:52<06:22,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1438/2008 [18:53<06:22,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1439/2008 [18:53<06:20,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1440/2008 [18:54<06:20,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1441/2008 [18:55<06:19,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1442/2008 [18:55<06:18,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1443/2008 [18:56<06:17,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1444/2008 [18:57<06:17,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1445/2008 [18:57<06:16,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1446/2008 [18:58<06:16,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1447/2008 [18:59<06:15,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1448/2008 [18:59<06:15,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1449/2008 [19:00<06:14,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1450/2008 [19:01<06:13,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1451/2008 [19:01<06:12,  1.50it/s]\u001b[A\n",
            "Iteration:  72% 1452/2008 [19:02<06:12,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1453/2008 [19:03<06:11,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1454/2008 [19:03<06:12,  1.49it/s]\u001b[A\n",
            "Iteration:  72% 1455/2008 [19:04<06:13,  1.48it/s]\u001b[A\n",
            "Iteration:  73% 1456/2008 [19:05<06:10,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1457/2008 [19:05<06:09,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1458/2008 [19:06<06:08,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1459/2008 [19:07<06:07,  1.50it/s]\u001b[A\n",
            "Iteration:  73% 1460/2008 [19:07<06:06,  1.50it/s]\u001b[A\n",
            "Iteration:  73% 1461/2008 [19:08<06:06,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1462/2008 [19:09<06:04,  1.50it/s]\u001b[A\n",
            "Iteration:  73% 1463/2008 [19:09<06:05,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1464/2008 [19:10<06:05,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1465/2008 [19:11<06:03,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1466/2008 [19:11<06:04,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1467/2008 [19:12<06:02,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1468/2008 [19:13<06:01,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1469/2008 [19:13<06:01,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1470/2008 [19:14<06:00,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1471/2008 [19:15<05:59,  1.50it/s]\u001b[A\n",
            "Iteration:  73% 1472/2008 [19:15<05:58,  1.50it/s]\u001b[A\n",
            "Iteration:  73% 1473/2008 [19:16<05:58,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1474/2008 [19:17<05:57,  1.49it/s]\u001b[A\n",
            "Iteration:  73% 1475/2008 [19:17<05:56,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1476/2008 [19:18<05:55,  1.50it/s]\u001b[A\n",
            "Iteration:  74% 1477/2008 [19:19<05:55,  1.50it/s]\u001b[A\n",
            "Iteration:  74% 1478/2008 [19:19<05:54,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1479/2008 [19:20<05:54,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1480/2008 [19:21<05:53,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1481/2008 [19:21<05:52,  1.50it/s]\u001b[A\n",
            "Iteration:  74% 1482/2008 [19:22<05:52,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1483/2008 [19:23<05:51,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1484/2008 [19:23<05:52,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1485/2008 [19:24<05:51,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1486/2008 [19:25<05:50,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1487/2008 [19:25<05:49,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1488/2008 [19:26<05:48,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1489/2008 [19:27<05:47,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1490/2008 [19:27<05:47,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1491/2008 [19:28<05:47,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1492/2008 [19:29<05:46,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1493/2008 [19:29<05:46,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1494/2008 [19:30<05:45,  1.49it/s]\u001b[A\n",
            "Iteration:  74% 1495/2008 [19:31<05:45,  1.49it/s]\u001b[A\n",
            "Iteration:  75% 1496/2008 [19:31<05:43,  1.49it/s]\u001b[A\n",
            "Iteration:  75% 1497/2008 [19:32<05:43,  1.49it/s]\u001b[A\n",
            "Iteration:  75% 1498/2008 [19:33<05:41,  1.49it/s]\u001b[A\n",
            "Iteration:  75% 1499/2008 [19:33<05:40,  1.49it/s]\u001b[A11/22/2020 13:31:28 - INFO - transformers.configuration_utils -   Configuration saved in ./ruGPT3medium_psy/checkpoint-1500/config.json\n",
            "11/22/2020 13:31:43 - INFO - transformers.modeling_utils -   Model weights saved in ./ruGPT3medium_psy/checkpoint-1500/pytorch_model.bin\n",
            "11/22/2020 13:31:43 - INFO - __main__ -   Saving model checkpoint to ./ruGPT3medium_psy/checkpoint-1500\n",
            "11/22/2020 13:32:53 - INFO - __main__ -   Saving optimizer and scheduler states to ./ruGPT3medium_psy/checkpoint-1500\n",
            "\n",
            "Iteration:  75% 1500/2008 [21:00<3:42:57, 26.33s/it]\u001b[A\n",
            "Iteration:  75% 1501/2008 [21:00<2:37:29, 18.64s/it]\u001b[A\n",
            "Iteration:  75% 1502/2008 [21:01<1:51:37, 13.24s/it]\u001b[A\n",
            "Iteration:  75% 1503/2008 [21:02<1:19:39,  9.46s/it]\u001b[A\n",
            "Iteration:  75% 1504/2008 [21:02<57:15,  6.82s/it]  \u001b[A\n",
            "Iteration:  75% 1505/2008 [21:03<41:38,  4.97s/it]\u001b[A\n",
            "Iteration:  75% 1506/2008 [21:04<30:43,  3.67s/it]\u001b[A\n",
            "Iteration:  75% 1507/2008 [21:04<23:05,  2.77s/it]\u001b[A\n",
            "Iteration:  75% 1508/2008 [21:05<17:44,  2.13s/it]\u001b[A\n",
            "Iteration:  75% 1509/2008 [21:05<13:59,  1.68s/it]\u001b[A\n",
            "Iteration:  75% 1510/2008 [21:06<11:22,  1.37s/it]\u001b[A\n",
            "Iteration:  75% 1511/2008 [21:07<09:31,  1.15s/it]\u001b[A\n",
            "Iteration:  75% 1512/2008 [21:07<08:15,  1.00it/s]\u001b[A\n",
            "Iteration:  75% 1513/2008 [21:08<07:21,  1.12it/s]\u001b[A\n",
            "Iteration:  75% 1514/2008 [21:09<06:43,  1.22it/s]\u001b[A\n",
            "Iteration:  75% 1515/2008 [21:09<06:16,  1.31it/s]\u001b[A\n",
            "Iteration:  75% 1516/2008 [21:10<05:57,  1.38it/s]\u001b[A\n",
            "Iteration:  76% 1517/2008 [21:11<05:44,  1.43it/s]\u001b[A\n",
            "Iteration:  76% 1518/2008 [21:11<05:34,  1.46it/s]\u001b[A\n",
            "Iteration:  76% 1519/2008 [21:12<05:27,  1.49it/s]\u001b[A\n",
            "Iteration:  76% 1520/2008 [21:13<05:24,  1.50it/s]\u001b[A\n",
            "Iteration:  76% 1521/2008 [21:13<05:21,  1.52it/s]\u001b[A\n",
            "Iteration:  76% 1522/2008 [21:14<05:20,  1.52it/s]\u001b[A\n",
            "Iteration:  76% 1523/2008 [21:14<05:17,  1.53it/s]\u001b[A\n",
            "Iteration:  76% 1524/2008 [21:15<05:15,  1.53it/s]\u001b[A\n",
            "Iteration:  76% 1525/2008 [21:16<05:13,  1.54it/s]\u001b[A\n",
            "Iteration:  76% 1526/2008 [21:16<05:11,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1527/2008 [21:17<05:10,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1528/2008 [21:18<05:10,  1.54it/s]\u001b[A\n",
            "Iteration:  76% 1529/2008 [21:18<05:09,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1530/2008 [21:19<05:08,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1531/2008 [21:20<05:07,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1532/2008 [21:20<05:08,  1.54it/s]\u001b[A\n",
            "Iteration:  76% 1533/2008 [21:21<05:06,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1534/2008 [21:22<05:06,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1535/2008 [21:22<05:05,  1.55it/s]\u001b[A\n",
            "Iteration:  76% 1536/2008 [21:23<05:04,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1537/2008 [21:24<05:04,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1538/2008 [21:24<05:03,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1539/2008 [21:25<05:02,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1540/2008 [21:25<05:03,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1541/2008 [21:26<05:01,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1542/2008 [21:27<05:01,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1543/2008 [21:27<05:01,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1544/2008 [21:28<05:01,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1545/2008 [21:29<04:59,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1546/2008 [21:29<04:59,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1547/2008 [21:30<04:58,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1548/2008 [21:31<04:57,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1549/2008 [21:31<04:56,  1.55it/s]\u001b[A\n",
            "Iteration:  77% 1550/2008 [21:32<04:57,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1551/2008 [21:33<04:55,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1552/2008 [21:33<04:56,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1553/2008 [21:34<04:55,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1554/2008 [21:35<04:54,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1555/2008 [21:35<04:53,  1.54it/s]\u001b[A\n",
            "Iteration:  77% 1556/2008 [21:36<04:53,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1557/2008 [21:36<04:52,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1558/2008 [21:37<04:51,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1559/2008 [21:38<04:51,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1560/2008 [21:38<04:50,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1561/2008 [21:39<04:50,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1562/2008 [21:40<04:49,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1563/2008 [21:40<04:48,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1564/2008 [21:41<04:48,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1565/2008 [21:42<04:47,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1566/2008 [21:42<04:47,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1567/2008 [21:43<04:46,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1568/2008 [21:44<04:46,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1569/2008 [21:44<04:45,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1570/2008 [21:45<04:44,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1571/2008 [21:46<04:44,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1572/2008 [21:46<04:44,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1573/2008 [21:47<04:44,  1.53it/s]\u001b[A\n",
            "Iteration:  78% 1574/2008 [21:48<04:42,  1.54it/s]\u001b[A\n",
            "Iteration:  78% 1575/2008 [21:48<04:42,  1.53it/s]\u001b[A\n",
            "Iteration:  78% 1576/2008 [21:49<04:42,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1577/2008 [21:50<04:41,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1578/2008 [21:50<04:41,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1579/2008 [21:51<04:39,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1580/2008 [21:51<04:38,  1.54it/s]\u001b[A\n",
            "Iteration:  79% 1581/2008 [21:52<04:38,  1.54it/s]\u001b[A\n",
            "Iteration:  79% 1582/2008 [21:53<04:37,  1.54it/s]\u001b[A\n",
            "Iteration:  79% 1583/2008 [21:53<04:37,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1584/2008 [21:54<04:36,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1585/2008 [21:55<04:36,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1586/2008 [21:55<04:35,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1587/2008 [21:56<04:35,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1588/2008 [21:57<04:34,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1589/2008 [21:57<04:34,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1590/2008 [21:58<04:33,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1591/2008 [21:59<04:33,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1592/2008 [21:59<04:31,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1593/2008 [22:00<04:31,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1594/2008 [22:01<04:30,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1595/2008 [22:01<04:29,  1.53it/s]\u001b[A\n",
            "Iteration:  79% 1596/2008 [22:02<04:29,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1597/2008 [22:03<04:28,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1598/2008 [22:03<04:28,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1599/2008 [22:04<04:28,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1600/2008 [22:05<04:27,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1601/2008 [22:05<04:27,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1602/2008 [22:06<04:25,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1603/2008 [22:07<04:25,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1604/2008 [22:07<04:24,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1605/2008 [22:08<04:24,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1606/2008 [22:08<04:23,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1607/2008 [22:09<04:22,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1608/2008 [22:10<04:21,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1609/2008 [22:10<04:22,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1610/2008 [22:11<04:20,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1611/2008 [22:12<04:21,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1612/2008 [22:12<04:19,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 1613/2008 [22:13<04:19,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1614/2008 [22:14<04:18,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1615/2008 [22:14<04:18,  1.52it/s]\u001b[A\n",
            "Iteration:  80% 1616/2008 [22:15<04:16,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1617/2008 [22:16<04:16,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1618/2008 [22:16<04:15,  1.52it/s]\u001b[A\n",
            "Iteration:  81% 1619/2008 [22:17<04:15,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1620/2008 [22:18<04:14,  1.52it/s]\u001b[A\n",
            "Iteration:  81% 1621/2008 [22:18<04:13,  1.52it/s]\u001b[A\n",
            "Iteration:  81% 1622/2008 [22:19<04:12,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1623/2008 [22:20<04:12,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1624/2008 [22:20<04:11,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1625/2008 [22:21<04:10,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1626/2008 [22:22<04:10,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1627/2008 [22:22<04:09,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1628/2008 [22:23<04:08,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1629/2008 [22:24<04:07,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1630/2008 [22:24<04:07,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1631/2008 [22:25<04:06,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1632/2008 [22:26<04:06,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1633/2008 [22:26<04:05,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1634/2008 [22:27<04:04,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1635/2008 [22:27<04:04,  1.53it/s]\u001b[A\n",
            "Iteration:  81% 1636/2008 [22:28<04:03,  1.53it/s]\u001b[A\n",
            "Iteration:  82% 1637/2008 [22:29<04:03,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1638/2008 [22:29<04:02,  1.53it/s]\u001b[A\n",
            "Iteration:  82% 1639/2008 [22:30<04:01,  1.53it/s]\u001b[A\n",
            "Iteration:  82% 1640/2008 [22:31<04:00,  1.53it/s]\u001b[A\n",
            "Iteration:  82% 1641/2008 [22:31<04:00,  1.53it/s]\u001b[A\n",
            "Iteration:  82% 1642/2008 [22:32<04:00,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1643/2008 [22:33<04:00,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1644/2008 [22:33<03:58,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1645/2008 [22:34<03:58,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1646/2008 [22:35<03:57,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1647/2008 [22:35<03:58,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1648/2008 [22:36<03:57,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1649/2008 [22:37<03:56,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1650/2008 [22:37<03:55,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1651/2008 [22:38<03:54,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1652/2008 [22:39<03:55,  1.51it/s]\u001b[A\n",
            "Iteration:  82% 1653/2008 [22:39<03:54,  1.51it/s]\u001b[A\n",
            "Iteration:  82% 1654/2008 [22:40<03:54,  1.51it/s]\u001b[A\n",
            "Iteration:  82% 1655/2008 [22:41<03:52,  1.52it/s]\u001b[A\n",
            "Iteration:  82% 1656/2008 [22:41<03:51,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1657/2008 [22:42<03:51,  1.51it/s]\u001b[A\n",
            "Iteration:  83% 1658/2008 [22:43<03:50,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1659/2008 [22:43<03:50,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1660/2008 [22:44<03:49,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1661/2008 [22:45<03:48,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1662/2008 [22:45<03:47,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1663/2008 [22:46<03:46,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1664/2008 [22:47<03:46,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1665/2008 [22:47<03:46,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1666/2008 [22:48<03:46,  1.51it/s]\u001b[A\n",
            "Iteration:  83% 1667/2008 [22:49<03:45,  1.51it/s]\u001b[A\n",
            "Iteration:  83% 1668/2008 [22:49<03:44,  1.51it/s]\u001b[A\n",
            "Iteration:  83% 1669/2008 [22:50<03:44,  1.51it/s]\u001b[A\n",
            "Iteration:  83% 1670/2008 [22:51<03:42,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1671/2008 [22:51<03:41,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1672/2008 [22:52<03:41,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1673/2008 [22:53<03:40,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1674/2008 [22:53<03:39,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1675/2008 [22:54<03:39,  1.52it/s]\u001b[A\n",
            "Iteration:  83% 1676/2008 [22:54<03:38,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1677/2008 [22:55<03:38,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1678/2008 [22:56<03:37,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1679/2008 [22:56<03:36,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1680/2008 [22:57<03:36,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1681/2008 [22:58<03:35,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1682/2008 [22:58<03:35,  1.51it/s]\u001b[A\n",
            "Iteration:  84% 1683/2008 [22:59<03:34,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1684/2008 [23:00<03:33,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1685/2008 [23:00<03:33,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1686/2008 [23:01<03:32,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1687/2008 [23:02<03:31,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1688/2008 [23:02<03:30,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1689/2008 [23:03<03:29,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1690/2008 [23:04<03:29,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1691/2008 [23:04<03:28,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1692/2008 [23:05<03:27,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1693/2008 [23:06<03:27,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1694/2008 [23:06<03:27,  1.52it/s]\u001b[A\n",
            "Iteration:  84% 1695/2008 [23:07<03:26,  1.51it/s]\u001b[A\n",
            "Iteration:  84% 1696/2008 [23:08<03:25,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1697/2008 [23:08<03:25,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1698/2008 [23:09<03:24,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1699/2008 [23:10<03:24,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1700/2008 [23:10<03:23,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1701/2008 [23:11<03:22,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1702/2008 [23:12<03:21,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1703/2008 [23:12<03:20,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1704/2008 [23:13<03:20,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1705/2008 [23:14<03:19,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1706/2008 [23:14<03:20,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1707/2008 [23:15<03:19,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1708/2008 [23:16<03:18,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1709/2008 [23:16<03:17,  1.52it/s]\u001b[A\n",
            "Iteration:  85% 1710/2008 [23:17<03:16,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1711/2008 [23:18<03:16,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1712/2008 [23:18<03:15,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1713/2008 [23:19<03:15,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1714/2008 [23:20<03:14,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1715/2008 [23:20<03:13,  1.51it/s]\u001b[A\n",
            "Iteration:  85% 1716/2008 [23:21<03:12,  1.52it/s]\u001b[A\n",
            "Iteration:  86% 1717/2008 [23:22<03:11,  1.52it/s]\u001b[A\n",
            "Iteration:  86% 1718/2008 [23:22<03:11,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1719/2008 [23:23<03:11,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1720/2008 [23:24<03:10,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1721/2008 [23:24<03:10,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1722/2008 [23:25<03:10,  1.50it/s]\u001b[A\n",
            "Iteration:  86% 1723/2008 [23:26<03:08,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1724/2008 [23:26<03:07,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1725/2008 [23:27<03:07,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1726/2008 [23:28<03:07,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1727/2008 [23:28<03:06,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1728/2008 [23:29<03:05,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1729/2008 [23:29<03:04,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1730/2008 [23:30<03:04,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1731/2008 [23:31<03:03,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1732/2008 [23:31<03:02,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1733/2008 [23:32<03:02,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1734/2008 [23:33<03:01,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1735/2008 [23:33<03:00,  1.51it/s]\u001b[A\n",
            "Iteration:  86% 1736/2008 [23:34<02:59,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1737/2008 [23:35<02:58,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1738/2008 [23:35<02:59,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1739/2008 [23:36<02:58,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1740/2008 [23:37<02:57,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1741/2008 [23:37<02:56,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1742/2008 [23:38<02:55,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1743/2008 [23:39<02:55,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1744/2008 [23:39<02:55,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1745/2008 [23:40<02:54,  1.50it/s]\u001b[A\n",
            "Iteration:  87% 1746/2008 [23:41<02:54,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1747/2008 [23:41<02:52,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1748/2008 [23:42<02:52,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1749/2008 [23:43<02:51,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1750/2008 [23:43<02:50,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1751/2008 [23:44<02:50,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1752/2008 [23:45<02:49,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1753/2008 [23:45<02:48,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1754/2008 [23:46<02:48,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1755/2008 [23:47<02:47,  1.51it/s]\u001b[A\n",
            "Iteration:  87% 1756/2008 [23:47<02:46,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1757/2008 [23:48<02:45,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1758/2008 [23:49<02:45,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1759/2008 [23:49<02:44,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1760/2008 [23:50<02:43,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1761/2008 [23:51<02:43,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1762/2008 [23:51<02:42,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1763/2008 [23:52<02:42,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1764/2008 [23:53<02:41,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1765/2008 [23:53<02:40,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1766/2008 [23:54<02:39,  1.52it/s]\u001b[A\n",
            "Iteration:  88% 1767/2008 [23:55<02:39,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1768/2008 [23:55<02:38,  1.52it/s]\u001b[A\n",
            "Iteration:  88% 1769/2008 [23:56<02:38,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1770/2008 [23:57<02:37,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1771/2008 [23:57<02:37,  1.50it/s]\u001b[A\n",
            "Iteration:  88% 1772/2008 [23:58<02:36,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1773/2008 [23:59<02:36,  1.50it/s]\u001b[A\n",
            "Iteration:  88% 1774/2008 [23:59<02:35,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1775/2008 [24:00<02:34,  1.50it/s]\u001b[A\n",
            "Iteration:  88% 1776/2008 [24:01<02:34,  1.51it/s]\u001b[A\n",
            "Iteration:  88% 1777/2008 [24:01<02:33,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1778/2008 [24:02<02:32,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1779/2008 [24:03<02:32,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1780/2008 [24:03<02:31,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1781/2008 [24:04<02:30,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1782/2008 [24:05<02:29,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1783/2008 [24:05<02:29,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1784/2008 [24:06<02:28,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1785/2008 [24:07<02:28,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1786/2008 [24:07<02:27,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1787/2008 [24:08<02:26,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1788/2008 [24:09<02:26,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1789/2008 [24:09<02:25,  1.51it/s]\u001b[A\n",
            "Iteration:  89% 1790/2008 [24:10<02:25,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1791/2008 [24:11<02:24,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1792/2008 [24:11<02:23,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1793/2008 [24:12<02:23,  1.49it/s]\u001b[A\n",
            "Iteration:  89% 1794/2008 [24:13<02:22,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1795/2008 [24:13<02:21,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1796/2008 [24:14<02:21,  1.50it/s]\u001b[A\n",
            "Iteration:  89% 1797/2008 [24:15<02:20,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1798/2008 [24:15<02:20,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1799/2008 [24:16<02:19,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 1800/2008 [24:17<02:19,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 1801/2008 [24:17<02:18,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1802/2008 [24:18<02:17,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1803/2008 [24:19<02:16,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1804/2008 [24:19<02:15,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1805/2008 [24:20<02:14,  1.51it/s]\u001b[A\n",
            "Iteration:  90% 1806/2008 [24:21<02:14,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1807/2008 [24:21<02:13,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1808/2008 [24:22<02:13,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 1809/2008 [24:23<02:13,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1810/2008 [24:23<02:12,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1811/2008 [24:24<02:11,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1812/2008 [24:25<02:10,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1813/2008 [24:25<02:09,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1814/2008 [24:26<02:09,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1815/2008 [24:27<02:08,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1816/2008 [24:27<02:07,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 1817/2008 [24:28<02:07,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1818/2008 [24:29<02:06,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1819/2008 [24:29<02:06,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1820/2008 [24:30<02:05,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1821/2008 [24:31<02:04,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1822/2008 [24:31<02:04,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1823/2008 [24:32<02:03,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1824/2008 [24:33<02:02,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1825/2008 [24:33<02:01,  1.51it/s]\u001b[A\n",
            "Iteration:  91% 1826/2008 [24:34<02:01,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1827/2008 [24:35<02:00,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1828/2008 [24:35<01:59,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1829/2008 [24:36<01:59,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1830/2008 [24:37<01:59,  1.49it/s]\u001b[A\n",
            "Iteration:  91% 1831/2008 [24:37<01:58,  1.49it/s]\u001b[A\n",
            "Iteration:  91% 1832/2008 [24:38<01:57,  1.49it/s]\u001b[A\n",
            "Iteration:  91% 1833/2008 [24:39<01:56,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1834/2008 [24:39<01:56,  1.49it/s]\u001b[A\n",
            "Iteration:  91% 1835/2008 [24:40<01:55,  1.49it/s]\u001b[A\n",
            "Iteration:  91% 1836/2008 [24:41<01:54,  1.50it/s]\u001b[A\n",
            "Iteration:  91% 1837/2008 [24:41<01:53,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1838/2008 [24:42<01:53,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1839/2008 [24:43<01:52,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1840/2008 [24:43<01:51,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1841/2008 [24:44<01:51,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1842/2008 [24:45<01:50,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1843/2008 [24:45<01:50,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1844/2008 [24:46<01:49,  1.49it/s]\u001b[A\n",
            "Iteration:  92% 1845/2008 [24:47<01:48,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1846/2008 [24:47<01:48,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1847/2008 [24:48<01:47,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1848/2008 [24:49<01:46,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1849/2008 [24:49<01:46,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1850/2008 [24:50<01:44,  1.51it/s]\u001b[A\n",
            "Iteration:  92% 1851/2008 [24:51<01:44,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1852/2008 [24:51<01:43,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1853/2008 [24:52<01:43,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1854/2008 [24:53<01:42,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1855/2008 [24:53<01:42,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1856/2008 [24:54<01:41,  1.50it/s]\u001b[A\n",
            "Iteration:  92% 1857/2008 [24:55<01:40,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1858/2008 [24:55<01:39,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1859/2008 [24:56<01:39,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1860/2008 [24:57<01:38,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1861/2008 [24:57<01:38,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1862/2008 [24:58<01:37,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1863/2008 [24:59<01:36,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1864/2008 [24:59<01:36,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1865/2008 [25:00<01:35,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1866/2008 [25:01<01:34,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1867/2008 [25:01<01:33,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1868/2008 [25:02<01:33,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1869/2008 [25:03<01:32,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1870/2008 [25:03<01:32,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1871/2008 [25:04<01:31,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1872/2008 [25:05<01:30,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1873/2008 [25:05<01:30,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1874/2008 [25:06<01:29,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1875/2008 [25:07<01:28,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1876/2008 [25:07<01:28,  1.50it/s]\u001b[A\n",
            "Iteration:  93% 1877/2008 [25:08<01:27,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1878/2008 [25:09<01:26,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1879/2008 [25:09<01:25,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1880/2008 [25:10<01:25,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1881/2008 [25:11<01:24,  1.51it/s]\u001b[A\n",
            "Iteration:  94% 1882/2008 [25:11<01:23,  1.51it/s]\u001b[A\n",
            "Iteration:  94% 1883/2008 [25:12<01:22,  1.51it/s]\u001b[A\n",
            "Iteration:  94% 1884/2008 [25:13<01:22,  1.51it/s]\u001b[A\n",
            "Iteration:  94% 1885/2008 [25:13<01:21,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1886/2008 [25:14<01:21,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1887/2008 [25:15<01:20,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1888/2008 [25:15<01:19,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1889/2008 [25:16<01:19,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1890/2008 [25:17<01:18,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1891/2008 [25:17<01:18,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1892/2008 [25:18<01:17,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1893/2008 [25:19<01:16,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1894/2008 [25:19<01:15,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1895/2008 [25:20<01:15,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1896/2008 [25:21<01:14,  1.50it/s]\u001b[A\n",
            "Iteration:  94% 1897/2008 [25:21<01:13,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1898/2008 [25:22<01:13,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1899/2008 [25:23<01:12,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1900/2008 [25:23<01:12,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1901/2008 [25:24<01:11,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1902/2008 [25:25<01:11,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1903/2008 [25:25<01:10,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1904/2008 [25:26<01:09,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1905/2008 [25:27<01:08,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1906/2008 [25:27<01:08,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1907/2008 [25:28<01:07,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1908/2008 [25:29<01:06,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1909/2008 [25:29<01:05,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1910/2008 [25:30<01:05,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1911/2008 [25:31<01:04,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1912/2008 [25:31<01:04,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1913/2008 [25:32<01:03,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1914/2008 [25:33<01:03,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1915/2008 [25:33<01:02,  1.50it/s]\u001b[A\n",
            "Iteration:  95% 1916/2008 [25:34<01:01,  1.49it/s]\u001b[A\n",
            "Iteration:  95% 1917/2008 [25:35<01:00,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1918/2008 [25:35<01:00,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1919/2008 [25:36<00:59,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1920/2008 [25:37<00:59,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1921/2008 [25:37<00:58,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1922/2008 [25:38<00:57,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1923/2008 [25:39<00:56,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1924/2008 [25:39<00:56,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1925/2008 [25:40<00:55,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1926/2008 [25:41<00:54,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1927/2008 [25:41<00:54,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1928/2008 [25:42<00:53,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1929/2008 [25:43<00:52,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1930/2008 [25:43<00:52,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1931/2008 [25:44<00:51,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1932/2008 [25:45<00:50,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1933/2008 [25:45<00:50,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1934/2008 [25:46<00:49,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1935/2008 [25:47<00:48,  1.49it/s]\u001b[A\n",
            "Iteration:  96% 1936/2008 [25:47<00:48,  1.50it/s]\u001b[A\n",
            "Iteration:  96% 1937/2008 [25:48<00:47,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1938/2008 [25:49<00:46,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1939/2008 [25:49<00:46,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1940/2008 [25:50<00:45,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1941/2008 [25:51<00:44,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1942/2008 [25:51<00:44,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1943/2008 [25:52<00:43,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1944/2008 [25:53<00:42,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1945/2008 [25:53<00:42,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1946/2008 [25:54<00:41,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1947/2008 [25:55<00:40,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1948/2008 [25:55<00:39,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1949/2008 [25:56<00:39,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1950/2008 [25:57<00:38,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1951/2008 [25:57<00:37,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1952/2008 [25:58<00:37,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1953/2008 [25:59<00:36,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1954/2008 [25:59<00:36,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1955/2008 [26:00<00:35,  1.50it/s]\u001b[A\n",
            "Iteration:  97% 1956/2008 [26:01<00:34,  1.49it/s]\u001b[A\n",
            "Iteration:  97% 1957/2008 [26:01<00:34,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1958/2008 [26:02<00:33,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1959/2008 [26:03<00:32,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1960/2008 [26:03<00:32,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1961/2008 [26:04<00:31,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1962/2008 [26:05<00:30,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1963/2008 [26:05<00:30,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1964/2008 [26:06<00:29,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1965/2008 [26:07<00:28,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1966/2008 [26:07<00:28,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1967/2008 [26:08<00:27,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1968/2008 [26:09<00:26,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1969/2008 [26:09<00:26,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1970/2008 [26:10<00:25,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1971/2008 [26:11<00:24,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1972/2008 [26:11<00:24,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1973/2008 [26:12<00:23,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1974/2008 [26:13<00:22,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1975/2008 [26:13<00:22,  1.49it/s]\u001b[A\n",
            "Iteration:  98% 1976/2008 [26:14<00:21,  1.50it/s]\u001b[A\n",
            "Iteration:  98% 1977/2008 [26:15<00:20,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1978/2008 [26:15<00:20,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1979/2008 [26:16<00:19,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1980/2008 [26:17<00:18,  1.49it/s]\u001b[A\n",
            "Iteration:  99% 1981/2008 [26:17<00:18,  1.49it/s]\u001b[A\n",
            "Iteration:  99% 1982/2008 [26:18<00:17,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1983/2008 [26:19<00:16,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1984/2008 [26:19<00:16,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1985/2008 [26:20<00:15,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1986/2008 [26:21<00:14,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1987/2008 [26:21<00:14,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1988/2008 [26:22<00:13,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1989/2008 [26:23<00:12,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1990/2008 [26:23<00:12,  1.49it/s]\u001b[A\n",
            "Iteration:  99% 1991/2008 [26:24<00:11,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1992/2008 [26:25<00:10,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1993/2008 [26:25<00:10,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1994/2008 [26:26<00:09,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1995/2008 [26:27<00:08,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1996/2008 [26:27<00:08,  1.50it/s]\u001b[A\n",
            "Iteration:  99% 1997/2008 [26:28<00:07,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 1998/2008 [26:29<00:06,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 1999/2008 [26:29<00:06,  1.50it/s]\u001b[A11/22/2020 13:38:24 - INFO - transformers.configuration_utils -   Configuration saved in ./ruGPT3medium_psy/checkpoint-2000/config.json\n",
            "11/22/2020 13:38:38 - INFO - transformers.modeling_utils -   Model weights saved in ./ruGPT3medium_psy/checkpoint-2000/pytorch_model.bin\n",
            "11/22/2020 13:38:38 - INFO - __main__ -   Saving model checkpoint to ./ruGPT3medium_psy/checkpoint-2000\n",
            "11/22/2020 13:39:49 - INFO - __main__ -   Saving optimizer and scheduler states to ./ruGPT3medium_psy/checkpoint-2000\n",
            "\n",
            "Iteration: 100% 2000/2008 [27:55<03:29, 26.21s/it]\u001b[A\n",
            "Iteration: 100% 2001/2008 [27:56<02:09, 18.56s/it]\u001b[A\n",
            "Iteration: 100% 2002/2008 [27:57<01:19, 13.18s/it]\u001b[A\n",
            "Iteration: 100% 2003/2008 [27:57<00:47,  9.42s/it]\u001b[A\n",
            "Iteration: 100% 2004/2008 [27:58<00:27,  6.79s/it]\u001b[A\n",
            "Iteration: 100% 2005/2008 [27:59<00:14,  4.95s/it]\u001b[A\n",
            "Iteration: 100% 2006/2008 [27:59<00:07,  3.65s/it]\u001b[A\n",
            "Iteration: 100% 2007/2008 [28:00<00:02,  2.75s/it]\u001b[A\n",
            "Iteration: 100% 2008/2008 [28:01<00:00,  1.19it/s]\n",
            "Epoch: 100% 1/1 [28:01<00:00, 1681.02s/it]\n",
            "11/22/2020 13:39:54 - INFO - __main__ -    global_step = 2008, average loss = 3.086858935743214\n",
            "11/22/2020 13:39:54 - INFO - __main__ -   Saving model checkpoint to ./ruGPT3medium_psy\n",
            "11/22/2020 13:39:54 - INFO - transformers.configuration_utils -   Configuration saved in ./ruGPT3medium_psy/config.json\n",
            "11/22/2020 13:40:34 - INFO - transformers.modeling_utils -   Model weights saved in ./ruGPT3medium_psy/pytorch_model.bin\n",
            "11/22/2020 13:40:38 - INFO - transformers.configuration_utils -   loading configuration file ./ruGPT3medium_psy/config.json\n",
            "11/22/2020 13:40:38 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"n_special\": 0,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/22/2020 13:40:38 - INFO - transformers.modeling_utils -   loading weights file ./ruGPT3medium_psy/pytorch_model.bin\n",
            "11/22/2020 13:40:52 - INFO - transformers.configuration_utils -   loading configuration file ./ruGPT3medium_psy/config.json\n",
            "11/22/2020 13:40:52 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"n_special\": 0,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   Model name './ruGPT3medium_psy' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming './ruGPT3medium_psy' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   Didn't find file ./ruGPT3medium_psy/added_tokens.json. We won't load it.\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/vocab.json\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/merges.txt\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   loading file None\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/special_tokens_map.json\n",
            "11/22/2020 13:40:52 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/tokenizer_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSCjGbhRhJf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438794e5-f5d2-4f45-b0c8-bf4869d3c8e2"
      },
      "source": [
        "!python ./ru-gpts/generate_transformers_tg_bot_trained.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-22 13:44:15.890768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   Model name './ruGPT3medium_psy' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming './ruGPT3medium_psy' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   Didn't find file ./ruGPT3medium_psy/added_tokens.json. We won't load it.\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/vocab.json\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/merges.txt\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   loading file None\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/special_tokens_map.json\n",
            "11/22/2020 13:44:19 - INFO - transformers.tokenization_utils -   loading file ./ruGPT3medium_psy/tokenizer_config.json\n",
            "11/22/2020 13:44:19 - INFO - transformers.configuration_utils -   loading configuration file ./ruGPT3medium_psy/config.json\n",
            "11/22/2020 13:44:19 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"n_special\": 0,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/22/2020 13:44:19 - INFO - transformers.modeling_utils -   loading weights file ./ruGPT3medium_psy/pytorch_model.bin\n",
            "11/22/2020 13:44:38 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=10, length=100, model_name_or_path='./ruGPT3medium_psy', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='', repetition_penalty=1.2, seed=42, stop_token='</s>', temperature=0.95, xlm_language='')\n",
            "11/22/2020 13:44:38 - INFO - apscheduler.scheduler -   Scheduler started\n",
            "11/22/2020 13:46:06 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "ruGPT:\n",
            "Привет! Меня зовут Вика и я очень нервничаю. Как мне справиться со стрессом?\n",
            "Вика, добрый день! Я бы хотела поделиться с вами информацией о том, как решить проблему: 1) Определитесь с тем, какой вид стресса вас беспокоит (например, вы можете ощущать себя эмоционально усталой или наоборот, у вас сильный негативный настрой); 2) Подумайте над вопросом «как избавиться от плохого настроения» – возможно, это поможет вам лучше понимать собственные чувства; 3) Попробуйте представить позитивное будущее в виде фильма или мультфильма. В этом случае вы увидите положительные изменения своего эмоцио\n",
            "76\n",
            "529\n",
            "11/22/2020 13:46:24 - INFO - telegram.ext.updater -   Received signal 2 (SIGINT), stopping...\n",
            "11/22/2020 13:46:24 - INFO - apscheduler.scheduler -   Scheduler has been shut down\n",
            "11/22/2020 13:46:24 - INFO - telegram.ext.updater -   Received signal 2 (SIGINT), stopping...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCT6Zn2S5u_h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}